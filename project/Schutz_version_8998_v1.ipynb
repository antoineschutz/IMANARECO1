{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy\n",
    "!pip install matplotlib\n",
    "!pip install scikit-image\n",
    "!pip install pillow\n",
    "!pip install opencv-python\n",
    "!pip install timm\n",
    "!pip install tqdm\n",
    "# Check is at least python 3.9\n",
    "import sys \n",
    "#assert (sys.version_info.major == 3) and (sys.version_info.minor == 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from typing import Callable\n",
    "import os\n",
    "from datetime import datetime\n",
    "from enum import Enum\n",
    "import random\n",
    "from skimage.color import rgb2gray, rgb2hsv\n",
    "from skimage import filters\n",
    "from skimage import segmentation\n",
    "from skimage.morphology import remove_small_holes, remove_small_objects\n",
    "import cv2 as cv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import timm\n",
    "import torchvision\n",
    "# from torchvision.models.vision_transformer import vit_b_16\n",
    "# from torchvision.models import ViT_B_16_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "\n",
    "# Get os name\n",
    "os_name = platform.system().lower()\n",
    "num_workers = 8\n",
    "\n",
    "# OS X\n",
    "if 'darwin' in os_name:\n",
    "    print(\"Detected OS X\")\n",
    "    %pip install torch==1.8.1 torchvision==0.9.1 torchaudio==0.8.1\n",
    "# Linux \n",
    "elif 'linux' in os_name:\n",
    "    print(\"Detected Linux\")\n",
    "    %pip install torch==1.8.1 torchvision==0.9.1 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "# Windows \n",
    "else:\n",
    "    print(\"Detected Windows\")\n",
    "    num_workers = 0  # Hard fix for Windows users\n",
    "    %pip install torch==1.12.0 torchvision==0.13 -f https://download.pytorch.org/whl/torch_stable.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "\n",
    "# Set the seed for reproducibility\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU.\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explanations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Segmentation\n",
    "\n",
    "For segmentation, we used the Circle Hough Transform (CHT) to isolate our coins. We used the open-cv with an improved implementation for better accuracy. Since our goal is not to miss any coins, we tweaked the parameters of the functions to be very sensitive to circles. So for each coin we have several circles. In order not to lose any information, we created a function `fitler_circles` to keep only the circle with the larger radius. \n",
    "\n",
    "Also, due to its high sensitivity, our segmentation can also return false positives (background classified as coin). For the training part, we extracted all the coins from the training data using this function. We manually labelled them and created an additional class for the false positives (background). We then trained a separate classifier to distinguish between a real coin and background.\n",
    "\n",
    "This part is a success, as almost all coins were successfully extracted and no false positives can fool our background classifier, allowing us to only deal with real coins during evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_circles(circle_array):\n",
    "    \"\"\"\n",
    "    Filter the input array of circles to return only the largest circle at each unique center coordinate.\n",
    "    \n",
    "    Parameters:\n",
    "    - circle_array (numpy.ndarray): A 2D array where each row represents a circle with the format [x_center, y_center, radius].\n",
    "    \n",
    "    Returns:\n",
    "    - numpy.ndarray: A 2D array containing only the largest circles at each unique center coordinate, with the same format as the input array.\n",
    "    \n",
    "    Description:\n",
    "    The function first identifies all unique center coordinates from the input array. \n",
    "    For each unique center, it then finds the circle with the largest radius among all circles with that center.\n",
    "    The result is a new array consisting of these largest circles, preserving the order of the first occurrence of each center in the input array.\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    # Find unique center coordinates\n",
    "    unique_centers, unique_indices = np.unique(circle_array[:, :2], axis=0, return_index=True)\n",
    "    \n",
    "    # Get the indices of circles with largest radius for each unique center\n",
    "    largest_circles = []\n",
    "    for center in unique_centers:\n",
    "      largest_circle = np.array((center[0], center[1], 0))\n",
    "      for j in range(len(circle_array)):\n",
    "        circle = circle_array[j]\n",
    "        if (circle[0] == center[0] and circle[1]==center[1] and circle[2] > largest_circle[2]):\n",
    "          largest_circle[2] = circle[2] \n",
    "      largest_circles.append(largest_circle)\n",
    "    \n",
    "    return np.array(largest_circles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the input is a cv image so x and y are swapped\n",
    "def extract_circles_images(x, y, r, img, down):\n",
    "    \"\"\"\n",
    "    Extracts and returns a sub-image centered around a specified circle with modified color channels.\n",
    "\n",
    "    Parameters:\n",
    "    - x (int): The x-coordinate of the circle's center.\n",
    "    - y (int): The y-coordinate of the circle's center.\n",
    "    - r (int): The radius of the circle.\n",
    "    - img (numpy.ndarray): The input image from which to extract the circle, assumed to be in BGR format.\n",
    "    - down (float): A scaling factor to adjust the size of the extracted area based on the circle's dimensions.\n",
    "\n",
    "    Returns:\n",
    "    - numpy.ndarray: The extracted sub-image \n",
    "    \"\"\"\n",
    "    factor = r+10 #TODO here , might have a huge impact\n",
    "    left = (x - factor)*down\n",
    "    right = (x + factor)*down\n",
    "    up = (y - factor)*down\n",
    "    bottom = (y + factor)*down\n",
    "    output = img.copy()\n",
    "    output[:, :, 0] = img[:, :, 2]\n",
    "    output[:, :, 2] = img[:, :, 0]\n",
    "    return output[up:bottom, left:right, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_circles(path, debug=False):\n",
    "    \"\"\"\n",
    "    Detects circles in an image, draws them on a copy of the image, and extracts these circles as separate images.\n",
    "    \n",
    "\n",
    "    Parameters:\n",
    "    - path (str): The file path to the image in which circles are to be detected.\n",
    "    - debug (bool, optional): If set to True, the function will display each circle's extracted image and the final\n",
    "      annotated image. \n",
    "\n",
    "    Returns:\n",
    "    - list of numpy.ndarray: A list containing the extracted images of detected circles.\n",
    "    \"\"\"\n",
    "\n",
    "    img = cv.imread(path)\n",
    "    full_size_img = img.copy()\n",
    "    down = 3  # downscale factor for processing\n",
    "\n",
    "    # Resize the image\n",
    "    size = (int(img.shape[1] / down), int(img.shape[0] / down))\n",
    "    img = cv.resize(img, size, interpolation=cv.INTER_LINEAR)\n",
    "\n",
    "    # Create a copy and swap color channels for visualization\n",
    "    output = img.copy()\n",
    "    output[:, :, 0] = img[:, :, 2]\n",
    "    output[:, :, 2] = img[:, :, 0]\n",
    "\n",
    "    img[:, :, 2] = 0\n",
    "\n",
    "    # Prepare image for circle detection\n",
    "    gray = cv.blur(cv.cvtColor(img, cv.COLOR_BGR2GRAY), (8, 8))\n",
    "\n",
    "    # Detect circles\n",
    "    circles = cv.HoughCircles(gray, cv.HOUGH_GRADIENT_ALT, dp=1, minDist=50,\n",
    "                              minRadius=50, maxRadius=200, param1=5, param2=0.6)\n",
    "\n",
    "    circles_imgs = []\n",
    "    if circles is not None:\n",
    "        # Filter and round circle parameters\n",
    "        circles = np.round(circles[0, :]).astype(\"int\")\n",
    "        circles = filter_circles(circles)\n",
    "        print(f\"Detected {len(circles)} circles\")\n",
    "\n",
    "        for (x, y, r) in circles:\n",
    "            # Draw circles and rectangles on the output\n",
    "            cv.circle(output, (x, y), r, (0, 255, 0), 4)\n",
    "            cv.rectangle(output, (x - 5, y - 5), (x + 5, y + 5), (0, 255, 0), -1)\n",
    "            # Extract and append each circle's image from the full-size image\n",
    "            new_circle = extract_circles_images(x, y, r, full_size_img, down)\n",
    "            circles_imgs.append(new_circle)\n",
    "            if debug:\n",
    "                # Display each circle's image if debugging\n",
    "                plt.imshow(new_circle)\n",
    "                plt.show()\n",
    "\n",
    "    if debug:\n",
    "        # Display the final output image with all circles drawn if debugging\n",
    "        plt.imshow(output)\n",
    "        plt.show()\n",
    "\n",
    "    return circles_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_data_paths():\n",
    "    \"\"\"\n",
    "    Returns the list of files for training.\n",
    "\n",
    "    Returns:\n",
    "    - list of str: A list containing the full paths to all files located within the subdirectories of the\n",
    "      training data base directory.\n",
    "    \"\"\"\n",
    "    training_paths = []  \n",
    "    base_dir = \"./data/iapr24-coin-counter/train/\"  \n",
    "\n",
    "    for d in os.listdir(base_dir):\n",
    "        training_dir = f\"{base_dir}/{d}\"  \n",
    "        for path in os.listdir(training_dir):\n",
    "            file_path = f\"{training_dir}/{path}\" \n",
    "            training_paths.append(file_path)  \n",
    "\n",
    "    return training_paths "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f'Using {device} for inference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet152 = torchvision.models.resnet152(weights=torchvision.models.ResNet152_Weights.IMAGENET1K_V2).to(device)\n",
    "feature_extractor = torch.nn.Sequential(*list(resnet152.children())[:-1])\n",
    "\n",
    "def extract_features(input_image):\n",
    "    \"\"\"\n",
    "    Extracts feature vectors from an input image using the ResNet-152 model pretrained on the ImageNet dataset.\n",
    "\n",
    "\n",
    "    Parameters:\n",
    "    - input_image (numpy.ndarray): The input image array.\n",
    "\n",
    "    Returns:\n",
    "    - torch.Tensor: A 1D tensor containing the extracted features from the image.\n",
    "    \"\"\"\n",
    "\n",
    "    # Set the feature extractor model to evaluation mode\n",
    "    feature_extractor.eval()\n",
    "\n",
    "    input_image = Image.fromarray(input_image)\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.CenterCrop(850),  # Center crop to 850x850\n",
    "        transforms.ToTensor(),       # Convert the image to a PyTorch tensor\n",
    "    ])\n",
    "    input_tensor = preprocess(input_image)  \n",
    "\n",
    "    input_batch = input_tensor.unsqueeze(0)\n",
    "\n",
    "    input_batch = input_batch.to(device)\n",
    "    feature_extractor.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        features = feature_extractor(input_batch)\n",
    "\n",
    "    features = torch.flatten(features)\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def freeze_first_layers(feature_extractor):\n",
    "    \"\"\"\n",
    "    Freezes the first 6 layers of the feature extrator \n",
    "    \"\"\"\n",
    "    for name, param in feature_extractor.named_parameters():\n",
    "        if not name.startswith(\"7.\"):\n",
    "            param.requires_grad = False\n",
    "    return feature_extractor\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "feature_extractor = freeze_first_layers(feature_extractor)\n",
    "\n",
    "for name, param in feature_extractor.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_data_paths():\n",
    "    \"\"\"\n",
    "    Returns the list of files for Testing.\n",
    "\n",
    "    Returns:\n",
    "    - list of str: A list containing the full paths to all files located within the subdirectories of the\n",
    "      testing data base directory.\n",
    "    \"\"\"\n",
    "    test_paths = []\n",
    "    base_dir = \"./data/iapr24-coin-counter/test/\"\n",
    "    for path in os.listdir(base_dir):\n",
    "        file_path = f\"{base_dir}/{path}\"\n",
    "        test_paths.append(file_path)\n",
    "    return test_paths\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training on individual coin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"chf_5\", \"chf_2\", \"chf_1\", \"chf_0.5\", \"chf_0.2\", \"chf_0.1\", \"chf_0.05\", \"eur_2\", \"eur_1\", \"eur_0.5\", \"eur_0.2\", \"eur_0.1\", \"eur_0.05\", \"eur_0.02\", \"eur_0.01\", \"OOD\", \"bg\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_set_size():\n",
    "    \"\"\"\n",
    "    Calculates and returns the total number training Files\n",
    "\n",
    "    Returns:\n",
    "    - int: The total number of files across all specified class directories, representing the size of the training set.\n",
    "    \"\"\"\n",
    "\n",
    "    size = 0  \n",
    "    labeled_coins_dir = \"./data/labeled_coins/\"  \n",
    "\n",
    "    for index, c in enumerate(class_names):\n",
    "        selected_dir = f\"{labeled_coins_dir}{c}\" \n",
    "        files = os.listdir(selected_dir)  \n",
    "        size += len(files)  \n",
    "\n",
    "    return size  \n",
    "\n",
    "print(get_training_set_size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### background classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_size = get_training_set_size()\n",
    "\n",
    "\n",
    "\n",
    "def prepare_training_data_bg():\n",
    "    \"\"\"\n",
    "    Prepares  training datasets for a background Classifier\n",
    "\n",
    "    Outputs:\n",
    "    - X_bg (torch.Tensor): A tensor filled with extracted features of each image.\n",
    "    - Y_bg (torch.Tensor): A tensor filled with labels for each image where '1' denote 'bg' and '0' denotes other classes.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    X_bg = torch.zeros((data_set_size, 2048)).to(device)\n",
    "    Y_bg = torch.zeros(data_set_size).to(device)\n",
    "    data_index = 0\n",
    "\n",
    "    for index, c in enumerate(class_names):\n",
    "        print(f\"extracting class {index}\")\n",
    "        labeled_coins_dir = \"./data/labeled_coins/\"\n",
    "        selected_dir = f\"{labeled_coins_dir}{c}\"\n",
    "        files = os.listdir(selected_dir)\n",
    "        for j, file in enumerate(files):\n",
    "            selected_file_path = f\"{selected_dir}/{file}\"\n",
    "            coin = Image.open(selected_file_path)\n",
    "            x = extract_features(np.array(coin))\n",
    "            X_bg[data_index] = x\n",
    "            val_y = 0\n",
    "            if (index == class_names.index(\"bg\")):\n",
    "                val_y = 1\n",
    "            Y_bg[data_index] = val_y\n",
    "\n",
    "            \n",
    "            data_index += 1\n",
    "    return X_bg,Y_bg\n",
    "\n",
    "\n",
    "X_bg,Y_bg = prepare_training_data_bg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "def train_test_classifier(classifier,criterion,optimizer,X,Y,nb_epochs,name,flatten_input = True,to_long =False):\n",
    "    \"\"\"\n",
    "    Trains a classifier on the given data and evaluates it using the specified criterion and optimizer.\n",
    "\n",
    "    Parameters:\n",
    "    classifier (torch.nn.Module): The neural network model to be trained.\n",
    "    criterion (torch.nn.Module): The loss function to be used for training.\n",
    "    optimizer (torch.optim.Optimizer): The optimizer used for updating the model parameters.\n",
    "    X (torch.Tensor): The input features for the dataset.\n",
    "    Y (torch.Tensor): The target labels for the dataset.\n",
    "    nb_epochs (int): The number of epochs for training the model.\n",
    "    name (str): The name identifier for the model, used for saving the best model and plotting.\n",
    "    to_long (Bool) : Set if the Y_prediction have to be cast to Long.\n",
    "    \"\"\"\n",
    "    \n",
    "    trainX, testX, trainY, testY = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "    if flatten_input:\n",
    "        trainY = trainY.unsqueeze(0).view(-1, 1)\n",
    "        testY = testY.unsqueeze(0).view(-1, 1)\n",
    "    train_losses= []\n",
    "    test_losses = []\n",
    "    best_test_loss = float('inf')\n",
    "    best_model_path = f'best_model_{name}.pth'\n",
    "\n",
    "    for epoch in tqdm(range(nb_epochs)):\n",
    "        optimizer.zero_grad()\n",
    "                \n",
    "        pred = classifier(trainX)\n",
    "        if to_long:\n",
    "            train_loss = criterion(pred, trainY.to(device).long()) \n",
    "        else :\n",
    "            train_loss = criterion(pred, trainY.to(device)) \n",
    "\n",
    "        train_loss.backward() \n",
    "        optimizer.step() \n",
    "\n",
    "        with torch.no_grad():\n",
    "            test_pred = classifier(testX)\n",
    "            if to_long:\n",
    "                test_loss = criterion(test_pred, testY.to(device).long()) \n",
    "            else :\n",
    "                test_loss = criterion(test_pred, testY.to(device)) \n",
    "            # Save losses for plotting\n",
    "        train_losses.append(train_loss.item())\n",
    "        test_losses.append(test_loss.item())\n",
    "\n",
    "        if test_loss.item() < best_test_loss:\n",
    "            best_test_loss = test_loss.item()\n",
    "            torch.save(classifier.state_dict(), best_model_path)\n",
    "\n",
    "    # Load the best model\n",
    "    # Create a new classifier instance and load the best model\n",
    "    best_classifier = copy.deepcopy(classifier)\n",
    "    best_classifier.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "    # Plotting the training and test losses\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(test_losses, label=f'Test Loss {name}')\n",
    "    plt.plot(train_losses, label=f'Train Loss {name}')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.yscale(\"log\")\n",
    "    plt.title(f\"Train and Test loss for the {name}\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    return best_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "def train_classifier(classifier,criterion,optimizer,X,Y,nb_epochs,name,flatten_input = True,to_long =False):\n",
    "    \"\"\"\n",
    "    Trains a classifier on the full data.\n",
    "\n",
    "    Parameters:\n",
    "    classifier (torch.nn.Module): The neural network model to be trained.\n",
    "    criterion (torch.nn.Module): The loss function to be used for training.\n",
    "    optimizer (torch.optim.Optimizer): The optimizer used for updating the model parameters.\n",
    "    X (torch.Tensor): The input features for the dataset.\n",
    "    Y (torch.Tensor): The target labels for the dataset.\n",
    "    nb_epochs (int): The number of epochs for training the model.\n",
    "    name (str): The name identifier for the model, used for saving the best model and plotting.\n",
    "    to_long (Bool) : Set if the Y_prediction have to be cast to Long.\n",
    "    \"\"\"\n",
    "    \n",
    "    if flatten_input:\n",
    "        Y = Y.unsqueeze(0).view(-1, 1)\n",
    "\n",
    "    train_losses= []\n",
    "\n",
    "\n",
    "    for epoch in tqdm(range(nb_epochs)):\n",
    "        optimizer.zero_grad()\n",
    "                \n",
    "        pred = classifier(X)\n",
    "        if to_long:\n",
    "            train_loss = criterion(pred, Y.to(device).long()) \n",
    "        else :\n",
    "            train_loss = criterion(pred, Y.to(device)) \n",
    "\n",
    "        train_loss.backward() \n",
    "        optimizer.step() \n",
    "\n",
    "\n",
    "        train_losses.append(train_loss.item())\n",
    "\n",
    "    # Plotting the training and test losses\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_losses, label=f'Train Loss {name}')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.yscale(\"log\")\n",
    "    plt.title(f\"Train loss for the {name}\")\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the binary classification model with a sequential neural network\n",
    "bg_classifier = torch.nn.Sequential( \n",
    "    torch.nn.Linear(in_features = 2048, out_features = 512), \n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(in_features = 512, out_features = 1), \n",
    "    torch.nn.Sigmoid()\n",
    ")\n",
    "bg_classifier = bg_classifier.to(device)\n",
    "criterion_bg = torch.nn.BCELoss()\n",
    "optimizer_bg = torch.optim.Adam(bg_classifier.parameters(), lr=5e-4)\n",
    "\n",
    "\n",
    "\n",
    "train_test_classifier(bg_classifier,criterion_bg,optimizer_bg,X_bg,Y_bg,1200,\"Background Classifier\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain the Bg classifier on the full data (splitting the data for test )\n",
    "bg_classifier = torch.nn.Sequential( \n",
    "    torch.nn.Linear(in_features = 2048, out_features = 512), \n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(in_features = 512, out_features = 1), \n",
    "    torch.nn.Sigmoid()\n",
    ")\n",
    "bg_classifier = bg_classifier.to(device)\n",
    "criterion_bg = torch.nn.BCELoss()\n",
    "optimizer_bg = torch.optim.Adam(bg_classifier.parameters(), lr=5e-4)\n",
    "\n",
    "\n",
    "\n",
    "train_classifier(bg_classifier,criterion_bg,optimizer_bg,X_bg,Y_bg,3000,\"Background Classifier\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training ood classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_coins_dir = \"./data/labeled_coins/\"\n",
    "data_set_size = get_training_set_size() - len(os.listdir(labeled_coins_dir+\"bg\"))\n",
    "\n",
    "def prepare_training_data_ood():\n",
    "    \"\"\"\n",
    "    Prepares  training datasets for a Out of Distribution Classifier\n",
    "\n",
    "    Outputs:\n",
    "    - X_ood (torch.Tensor): A tensor filled with extracted features of each image.\n",
    "    - Y_ood (torch.Tensor): A tensor filled with labels for each image where '1' denote 'out of distriubtion' and '0' denotes others.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    X_ood = torch.zeros((data_set_size, 2048)).to(device)\n",
    "    Y_ood = torch.zeros(data_set_size).to(device)\n",
    "\n",
    "    data_index = 0\n",
    "\n",
    "    for index, c in enumerate(class_names):\n",
    "        if index == len(class_names) - 1: continue\n",
    "        print(f\"extracting class {index}\")\n",
    "        labeled_coins_dir = \"./data/labeled_coins/\"\n",
    "        selected_dir = f\"{labeled_coins_dir}{c}\"\n",
    "        files = os.listdir(selected_dir)\n",
    "        for j, file in enumerate(files):\n",
    "            selected_file_path = f\"{selected_dir}/{file}\"\n",
    "            coin = Image.open(selected_file_path)\n",
    "            x = extract_features(np.array(coin))\n",
    "            X_ood[data_index] = x\n",
    "            val_y = 0\n",
    "            if (index == class_names.index(\"OOD\")):\n",
    "                val_y = 1\n",
    "            Y_ood[data_index] = val_y\n",
    "\n",
    "            \n",
    "            data_index += 1\n",
    "    return X_ood,Y_ood\n",
    "\n",
    "\n",
    " \n",
    "X_ood,Y_ood = prepare_training_data_ood()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ood_classifier = torch.nn.Sequential( \n",
    "    torch.nn.Linear(in_features = 2048, out_features = 512), \n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(in_features = 512, out_features = 1), \n",
    "    torch.nn.Sigmoid()\n",
    ")\n",
    "\n",
    "ood_classifier = ood_classifier.to(device)\n",
    "\n",
    "\n",
    "criterion_ood = torch.nn.BCELoss()\n",
    "selected_param = list(filter(lambda p: p.requires_grad, feature_extractor.parameters()))\n",
    "\n",
    "\n",
    "optimizer_ood = torch.optim.Adam(list(ood_classifier.parameters()) + selected_param, lr=5e-4)\n",
    "\n",
    "\n",
    "train_test_classifier(ood_classifier,criterion_ood,optimizer_ood,X_ood,Y_ood,2000,\"Ood Classifier\")\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Full data training\n",
    "ood_classifier = torch.nn.Sequential( \n",
    "    torch.nn.Linear(in_features = 2048, out_features = 512), \n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(in_features = 512, out_features = 1), \n",
    "    torch.nn.Sigmoid()\n",
    ")\n",
    "\n",
    "ood_classifier = ood_classifier.to(device)\n",
    "\n",
    "\n",
    "criterion_ood = torch.nn.BCELoss()\n",
    "selected_param = list(filter(lambda p: p.requires_grad, feature_extractor.parameters()))\n",
    "\n",
    "\n",
    "optimizer_ood = torch.optim.Adam(list(ood_classifier.parameters()) + selected_param, lr=5e-4)\n",
    "\n",
    "\n",
    "train_classifier(ood_classifier,criterion_ood,optimizer_ood,X_ood,Y_ood,3000,\"Ood Classifier\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training chf/eur classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_coins_dir = \"./data/labeled_coins/\"\n",
    "data_set_size = get_training_set_size() - len(os.listdir(labeled_coins_dir+\"bg\")) - len(os.listdir(labeled_coins_dir+\"OOD\"))\n",
    "\n",
    "def prepare_training_data_chf_eur(return_test_images=False):\n",
    "    # for more detailed investigation assign half of the training subset for validation \n",
    "    X_chf_eur_train = []\n",
    "    X_chf_eur_test = []\n",
    "    Y_chf_eur_train = []\n",
    "    Y_chf_eur_test = []\n",
    "    imgs_test = []\n",
    "\n",
    "    for index, c in enumerate(class_names):\n",
    "        if index >= len(class_names) - 2: continue\n",
    "\n",
    "        print(f\"extracting class {index}\")\n",
    "        selected_dir = f\"{labeled_coins_dir}{c}\"\n",
    "        files = os.listdir(selected_dir)\n",
    "        n_train = len(files) / 2\n",
    "        for j, file in enumerate(files):\n",
    "            target = torch.tensor([index]).to(device)\n",
    "\n",
    "            selected_file_path = f\"{selected_dir}/{file}\"\n",
    "            coin = Image.open(selected_file_path)\n",
    "            x = extract_features(np.array(coin))\n",
    "            if j <= n_train:\n",
    "                X_chf_eur_train.append(x)\n",
    "                Y_chf_eur_train.append(index)\n",
    "            else:\n",
    "                X_chf_eur_test.append(x)\n",
    "                Y_chf_eur_test.append(index)\n",
    "                imgs_test.append(coin)\n",
    "                \n",
    "    X_chf_eur_train = torch.stack(X_chf_eur_train).to(device)\n",
    "    X_chf_eur_test = torch.stack(X_chf_eur_test).to(device)\n",
    "    Y_chf_eur_train = torch.tensor(Y_chf_eur_train).to(device)\n",
    "    Y_chf_eur_test = torch.tensor(Y_chf_eur_test).to(device)\n",
    "\n",
    "    if return_test_images:\n",
    "        return X_chf_eur_train, X_chf_eur_test, Y_chf_eur_train, Y_chf_eur_test, imgs_test\n",
    "    return X_chf_eur_train, X_chf_eur_test, Y_chf_eur_train, Y_chf_eur_test\n",
    "\n",
    "X_chf_eur_train, X_chf_eur_test, Y_chf_eur_train, Y_chf_eur_test, imgs_test = prepare_training_data_chf_eur(return_test_images=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = torch.nn.Sequential( \n",
    "    torch.nn.Linear(in_features = 2048, out_features = 512), \n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(in_features = 512, out_features = 15), \n",
    ")\n",
    "\n",
    "linear = linear.to(device)\n",
    "\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(list(linear.parameters())+selected_param, lr=5e-4)\n",
    "\n",
    "train_classifier(linear,criterion,optimizer,X_chf_eur_train,Y_chf_eur_train,400,\"chf_eur Classifier\",flatten_input=False,to_long = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "labels = [\"5CHF\",\"2CHF\",\"1CHF\",\"0.5CHF\",\"0.2CHF\",\"0.1CHF\",\"0.05CHF\",\"2EUR\",\"1EUR\",\"0.5EUR\",\"0.2EUR\",\"0.1EUR\",\"0.05EUR\",\"0.02EUR\",\"0.01EUR\"]\n",
    "def test_classifier(classifier,X_test,Y_test,name,plot_conf_matrix=True):\n",
    "    \"\"\"\n",
    "    Computes accuracy and (optionally) confusion matrix for a trained model \n",
    "\n",
    "    Parameters:\n",
    "    classifier (torch.nn.Module): The trained neural network.\n",
    "    X_test (torch.Tensor): The input features for the test dataset.\n",
    "    Y_test (torch.Tensor): The target labels for the test dataset.\n",
    "    name (str): The name identifier for the model, used for plotting.\n",
    "    plot_conf_matrix(bool): whether to display the confusion matrix or not\n",
    "\n",
    "    \"\"\"\n",
    "    Y_test = Y_test.detach().cpu().numpy()\n",
    "    with torch.no_grad():\n",
    "        classifier.eval()\n",
    "        pred = classifier(X_test).detach().cpu().numpy()\n",
    "    \n",
    "    Y_pred = np.argmax(pred, axis=1)\n",
    "    print(f\"Accuracy score for {name}: {accuracy_score(Y_test, Y_pred)}\")\n",
    "    \n",
    "    if plot_conf_matrix:\n",
    "        conf_matrix = confusion_matrix(Y_test, Y_pred)\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        sns.heatmap(conf_matrix, xticklabels=labels, yticklabels=labels, annot=True)\n",
    "        plt.xlabel('Predicted labels')\n",
    "        plt.ylabel('True labels')\n",
    "        plt.title(f\"Confusion matrix for {name}\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_classifier(linear, X_chf_eur_test, Y_chf_eur_test, \"chf_eur Classifier\", plot_conf_matrix=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the validation accuracy and confusion matrix, we observe that 1. overall, accuracy of predictions is high 2. there are still groups of classes that are hard for the model to distinguish between:\n",
    "- 0.5 chf - 0.2 chf - 0.1 chf\n",
    "- 1 chf - 2 chf\n",
    "- 0.05 euro - 0.02 euro - 0.01 euro \n",
    "- 1 euro - 2 euro \n",
    "\n",
    "By calculating the coin’s radius, we can use this additional feature to more accurately differentiate between similar-looking coins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_coins_dir = \"./data/labeled_coins/\"\n",
    "data_set_size = get_training_set_size() - len(os.listdir(labeled_coins_dir+\"bg\")) - len(os.listdir(labeled_coins_dir+\"OOD\"))\n",
    "\n",
    "\n",
    "def prepare_training_data_chf_eur():\n",
    "\n",
    "    X_chf_eur = torch.zeros((data_set_size, 2048)).to(device)\n",
    "    Y_chf_eur = torch.zeros(data_set_size).to(device)\n",
    "\n",
    "    data_index = 0\n",
    "\n",
    "\n",
    "    for index, c in enumerate(class_names):\n",
    "        if index >= len(class_names) - 2: continue\n",
    "\n",
    "        print(f\"extracting class {index}\")\n",
    "        selected_dir = f\"{labeled_coins_dir}{c}\"\n",
    "        files = os.listdir(selected_dir)\n",
    "        for j, file in enumerate(files):\n",
    "            target = torch.tensor([index]).to(device)\n",
    "\n",
    "            selected_file_path = f\"{selected_dir}/{file}\"\n",
    "            coin = Image.open(selected_file_path)\n",
    "            x = extract_features(np.array(coin))\n",
    "            X_chf_eur[data_index] = x\n",
    "            Y_chf_eur[data_index] = index\n",
    "\n",
    "            \n",
    "            data_index += 1\n",
    "    return X_chf_eur,Y_chf_eur\n",
    "X_chf_eur,Y_chf_eur = prepare_training_data_chf_eur()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = torch.nn.Sequential( \n",
    "    torch.nn.Linear(in_features = 2048, out_features = 512), \n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(in_features = 512, out_features = 15), \n",
    ")\n",
    "\n",
    "linear = linear.to(device)\n",
    "\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss() \n",
    "optimizer = torch.optim.Adam(list(linear.parameters())+selected_param, lr=5e-4)\n",
    "\n",
    "train_test_classifier(linear,criterion,optimizer,X_chf_eur,Y_chf_eur,300,\"chf_eur Classifier\",flatten_input=False,to_long = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Full data Training\n",
    "\n",
    "linear = torch.nn.Sequential( \n",
    "    torch.nn.Linear(in_features = 2048, out_features = 512), \n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(in_features = 512, out_features = 15), \n",
    ")\n",
    "\n",
    "linear = linear.to(device)\n",
    "\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(list(linear.parameters())+selected_param, lr=5e-4)\n",
    "\n",
    "train_classifier(linear,criterion,optimizer,X_chf_eur,Y_chf_eur,400,\"chf_eur Classifier\",flatten_input=False,to_long = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_header = \"id,5CHF,2CHF,1CHF,0.5CHF,0.2CHF,0.1CHF,0.05CHF,2EUR,1EUR,0.5EUR,0.2EUR,0.1EUR,0.05EUR,0.02EUR,0.01EUR,OOD\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_to_filename(path):\n",
    "    return path.split(\"/\")[-1].split(\".\")[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### filter functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_radius(coin, min_radius, max_radius,down=2 ,debug=False):\n",
    "    \"\"\"\n",
    "    Finds the radius of the the coin in the image.\n",
    "\n",
    "    Args:\n",
    "        coin (ndarray): The input image containing the coin.\n",
    "        min_radius (float): The minimum expected radius of the coin.\n",
    "        max_radius (float): The maximum expected radius of the coin.\n",
    "        debug (bool, optional): If True, displays debug information and visualization. Default is False.\n",
    "\n",
    "    Returns:\n",
    "        int: The radius of the detected coin. Returns 0 if no circle is found.\n",
    "    \"\"\"\n",
    "    img = (rgb2gray(coin)*255).astype(np.uint8)\n",
    "    img = cv.blur(img, (16, 16))[::down, ::down]\n",
    "    \n",
    "    min_r = int((min_radius*0.9)//down)\n",
    "    max_r = int((max_radius*1.5)//down)\n",
    "    \n",
    "    circle = cv.HoughCircles(img, cv.HOUGH_GRADIENT_ALT, dp=1, minDist = 50, minRadius=min_r, maxRadius=max_r, param1=50, param2=0.8)\n",
    "    \n",
    "    if circle is not None:\n",
    "        circles = np.round(circle[0, :]).astype(\"int\")\n",
    "        circles = filter_circles(circles)\n",
    "    \n",
    "        for (x, y, r) in circles:\n",
    "            # print(x, y, r)\n",
    "            # draw the circle in the output image, then draw a rectangle\n",
    "                # corresponding to the center of the circle\n",
    "            radius = down*r\n",
    "            if False: #TODO ANTOINE\n",
    "                cv.circle(coin, (down*x, down*y), down*r, (0, 255, 0), 4)\n",
    "                plt.title(f\"radius: {radius}\")\n",
    "                plt.imshow(coin)\n",
    "                plt.show()\n",
    "            return radius\n",
    "    else:\n",
    "        if debug:\n",
    "            print(\"no circle found\")\n",
    "        return 0\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_radius_eur_cents(coin, min_radius, max_radius, debug=False):\n",
    "    return find_radius(coin,min_radius,max_radius,down=3,debug=debug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_chf_cents(coin, pred_class, debug=False):\n",
    "    \"\"\"\n",
    "    Determines the class of a Swiss coin based on its radius.\n",
    "    This functions is speciliazed for 50,20 and 10 cents.\n",
    "\n",
    "    Parameters:\n",
    "    coin (array-like): The coin image.\n",
    "    pred_class (int): The initial predicted class of the coin.\n",
    "    debug (bool, optional): If True, prints debug information. Default is False.\n",
    "\n",
    "    Returns:\n",
    "    int: The predicted class of the coin. Possible values are:\n",
    "         - 3 for 50 cents\n",
    "         - 4 for 20 cents\n",
    "         - 5 for 10 cents\n",
    "\n",
    "    Notes:\n",
    "    - The function calculates the coin's radius using the `find_radius` function.\n",
    "    - If the calculated radius is less than 150, the function returns the initial predicted class.\n",
    "    - The function then determines the closest matching class based on predefined radii for 50, 20, and 10 cent coins.\n",
    "    \"\"\"\n",
    "    previous_class = pred_class\n",
    "    cents_20_radius = 240\n",
    "    cents_10_radius = 228\n",
    "    cents_50_radius = 208\n",
    "    \n",
    "    radius = find_radius(coin, min_radius=cents_50_radius, max_radius=cents_10_radius, debug=debug)\n",
    "    if radius < 150: return pred_class\n",
    "        \n",
    "    values = np.array((cents_50_radius, cents_20_radius, cents_10_radius))\n",
    "    classes = [3, 4, 5]\n",
    "    pred = classes[np.argmin(np.abs(values - radius))]\n",
    "    if debug:\n",
    "        print(f\"returning {class_names[pred]}, before {class_names[previous_class]}\")\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_chf_francs(coin, pred_class, debug=False):\n",
    "    \"\"\"\n",
    "    Determines the class of a Swiss coin based on its radius.\n",
    "    This functions is speciliazed for 1 and 2 swiss franc.\n",
    "\n",
    "    Parameters:\n",
    "    coin (array-like): The coin image.\n",
    "    pred_class (int): The initial predicted class of the coin.\n",
    "    debug (bool, optional): If True, prints debug information. Default is False.\n",
    "\n",
    "    Returns:\n",
    "    int: The predicted class of the coin. Possible values are:\n",
    "         - 1 for 2 francs\n",
    "         - 2 for 1 franc\n",
    "\n",
    "    Notes:\n",
    "\n",
    "    - The function calculates the coin's radius using the `find_radius`.\n",
    "    - If the calculated radius is less than 240, the function returns the initial predicted class.\n",
    "    - The function then determines the closest matching class based on predefined radii for 2 franc and 1 franc coins.\n",
    "    \"\"\"\n",
    "    francs_2_radius = 315\n",
    "    francs_1_radius = 265\n",
    "    \n",
    "    radius = find_radius(coin, min_radius=francs_1_radius, max_radius=francs_2_radius, debug=debug)\n",
    "    if radius < 240: return pred_class\n",
    "        \n",
    "    values = np.array((francs_2_radius, francs_1_radius))\n",
    "    classes = [1, 2]\n",
    "    pred = classes[np.argmin(np.abs(values - radius))]\n",
    "    if debug:\n",
    "        print(f\"returning {class_names[pred]} - before {class_names[pred_class]}\")\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_eur_cents(coin, pred_class, debug=False):\n",
    "    \"\"\"\n",
    "    Determines the class of a Euro cent coin based on its radius.\n",
    "\n",
    "    Parameters:\n",
    "    coin (array-like): The coin image.\n",
    "    pred_class (int): The initial predicted class of the coin.\n",
    "    debug (bool, optional): If True, prints debug information. Default is False.\n",
    "\n",
    "    Returns:\n",
    "    int: The predicted class of the coin. Possible values are:\n",
    "         - 12 for 5 cents\n",
    "         - 13 for 2 cents\n",
    "         - 14 for 1 cent\n",
    "\n",
    "    Notes:\n",
    "    - The function calculates the coin's radius using the `find_radius_eur_cents`.\n",
    "    - If the calculated radius is less than 170, the function returns the initial predicted class.\n",
    "    - The function then determines the closest matching class based on predefined radii for 5, 2, and 1 cent coins.\n",
    "    \"\"\"\n",
    "    cents_1_radius = 192\n",
    "    cents_2_radius = 222\n",
    "    cents_5_radius = 249\n",
    "    \n",
    "    radius = find_radius_eur_cents(coin, min_radius=cents_1_radius, max_radius=cents_5_radius, debug=debug)\n",
    "    if radius < 170: return pred_class\n",
    "        \n",
    "    values = np.array((cents_5_radius, cents_2_radius, cents_1_radius))\n",
    "    classes = [12, 13, 14]\n",
    "    pred = classes[np.argmin(np.abs(values - radius))]\n",
    "    if debug:\n",
    "        print(f\"returning {class_names[pred]} - before {class_names[pred_class]}\")\n",
    "    return pred\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_eur_1_2(coin, pred_class, debug=False):\n",
    "    \"\"\"\n",
    "    Determines the class of a Euro 1 or 2 coin based on its radius.\n",
    "\n",
    "    Parameters:\n",
    "    coin (array-like): The coin image.\n",
    "    pred_class (int): The initial predicted class of the coin.\n",
    "    debug (bool, optional): If True, prints debug information. Default is False.\n",
    "\n",
    "    Returns:\n",
    "    int: The predicted class of the coin. Possible values are:\n",
    "         - 7 for 2 euros\n",
    "         - 8 for 1 euro\n",
    "\n",
    "    Notes:\n",
    "    - The function calculates the coin's radius using the `find_radius` function.\n",
    "    - If the calculated radius is less than 240, the function returns the initial predicted class.\n",
    "    - The function then determines the closest matching class based on predefined radii for 2 euro and 1 euro coins.\n",
    "    \"\"\"\n",
    "    eur_2_radius = 292\n",
    "    eur_1_radius = 266\n",
    "    \n",
    "    \n",
    "    \n",
    "    radius = find_radius(coin, min_radius=eur_1_radius, max_radius=eur_2_radius, debug=debug)\n",
    "    if radius < 240: return pred_class\n",
    "        \n",
    "    values = np.array((eur_2_radius, eur_1_radius))\n",
    "    classes = [7, 8]\n",
    "    pred = classes[np.argmin(np.abs(values - radius))]\n",
    "    if debug:\n",
    "        print(f\"returning {class_names[pred]} - before {class_names[pred_class]}\")\n",
    "    return pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = csv_header\n",
    "csv_file += \"\\n\"\n",
    "with torch.no_grad():\n",
    "    linear.eval()\n",
    "    ood_classifier.eval()\n",
    "    bg_classifier.eval()\n",
    "\n",
    "    for i, path in enumerate(get_test_data_paths()):\n",
    "        print(path)\n",
    "    \n",
    "\n",
    "        coins = find_circles(path)        \n",
    "        p = np.zeros(16, dtype=np.uint8)\n",
    "        for coin in coins:\n",
    "  \n",
    "            shape = coin.shape\n",
    "            if shape[0] <10 or shape[1]<10: continue\n",
    "\n",
    "            x = extract_features(coin).to(device)\n",
    "            x = torch.unsqueeze(x, 0)\n",
    "\n",
    "            bg_pred = bg_classifier(x)\n",
    "            bg_class_pred = torch.round(bg_pred).item()\n",
    "            if bg_class_pred == 1: continue\n",
    "\n",
    "\n",
    "\n",
    "            ood_pred = ood_classifier(x)\n",
    "            ood_class_pred = torch.round(ood_pred).item()\n",
    "            if ood_class_pred == 1:\n",
    "                p[15] += 1\n",
    "                continue\n",
    "            \n",
    "\n",
    "            \n",
    "            \n",
    "            pred_test = linear(x).flatten()\n",
    "            pred_class = torch.argmax(pred_test)\n",
    "            \n",
    "           \n",
    "            \n",
    "            \n",
    "            \n",
    "            if pred_class==3 or pred_class == 4 or pred_class == 5:\n",
    "                pred_class = test_chf_cents(coin, pred_class.item(), debug=True)\n",
    "            if pred_class == 12 or pred_class == 13 or pred_class == 14:\n",
    "                \n",
    "                pred_class = test_eur_cents(coin, pred_class.item(),debug=True)\n",
    "                \n",
    "            elif pred_class == 7 or pred_class == 8:\n",
    "                \n",
    "                pred_class = test_eur_1_2(coin, pred_class.item(),debug=True)\n",
    "\n",
    "            \n",
    "            elif pred_class == 1 or pred_class == 2:\n",
    "                pred_class = test_chf_francs(coin, pred_class.item(),debug=True)\n",
    "            \n",
    "          \n",
    "            \n",
    "            p[pred_class] += 1\n",
    "\n",
    "        \n",
    "\n",
    "        p_string = np.array2string(p, separator=', ', precision=0).replace(\"[\", \"\").replace(\"]\", \"\")\n",
    "        csv_row = f\"{path_to_filename(path)},{p_string}\"\n",
    "        print(csv_row)\n",
    "        csv_file += csv_row\n",
    "        csv_file += \"\\n\"\n",
    "\n",
    "with open('./data/sub_3000_3000_400.csv', 'w') as file:\n",
    "    file.write(csv_file)\n",
    "    \n",
    "file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iapr_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
