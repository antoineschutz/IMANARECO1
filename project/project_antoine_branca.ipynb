{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy\n",
    "!pip install matplotlib\n",
    "!pip install scikit-image\n",
    "!pip install pillow\n",
    "!pip install opencv-python\n",
    "!pip install timm\n",
    "!pip install tqdm\n",
    "# Check is at least python 3.9\n",
    "import sys \n",
    "assert (sys.version_info.major == 3) and (sys.version_info.minor == 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from typing import Callable\n",
    "import os\n",
    "from datetime import datetime\n",
    "from enum import Enum\n",
    "import random\n",
    "from skimage.color import rgb2gray, rgb2hsv\n",
    "from skimage import filters\n",
    "from skimage import segmentation\n",
    "from skimage.morphology import remove_small_holes, remove_small_objects\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import timm\n",
    "import torchvision\n",
    "from torchvision.models.vision_transformer import vit_b_16\n",
    "from torchvision.models import ViT_B_16_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "\n",
    "# Get os name\n",
    "os_name = platform.system().lower()\n",
    "num_workers = 8\n",
    "\n",
    "# OS X\n",
    "if 'darwin' in os_name:\n",
    "    print(\"Detected OS X\")\n",
    "    %pip install torch==1.8.1 torchvision==0.9.1 torchaudio==0.8.1\n",
    "# Linux \n",
    "elif 'linux' in os_name:\n",
    "    print(\"Detected Linux\")\n",
    "    %pip install torch==1.8.1 torchvision==0.9.1 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "# Windows \n",
    "else:\n",
    "    print(\"Detected Windows\")\n",
    "    num_workers = 0  # Hard fix for Windows users\n",
    "    %pip install torch==1.12.0 torchvision==0.13 -f https://download.pytorch.org/whl/torch_stable.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageType(Enum):\n",
    "    NEUTRAL = \"1. neutral_bg\"\n",
    "    NOISY = \"2. noisy_bg\"\n",
    "    HAND = \"3. hand\"\n",
    "    NEUTRAL_OOD = \"4. neutral_bg_outliers\"\n",
    "    NOISY_OOD = \"5. noisy_bg_outliers\"\n",
    "    HAND_OOD = \"6. hand_outliers\"\n",
    "    \n",
    "def loadImageOfType(type: ImageType, downsample: int = 1, grayscale: bool = False):\n",
    "    # directory = f\"./data/train/{type}\"\n",
    "    directory = os.path.join(\".\", \"data\", \"train\", type.value)\n",
    "    images = os.listdir(directory)\n",
    "    img = np.array(Image.open(os.path.join(directory, random.choice(images)))) \n",
    "    if downsample > 1:\n",
    "        img = img[::downsample, ::downsample, :]\n",
    "    if grayscale:\n",
    "        img = (rgb2gray(img)*255).astype(np.uint8)\n",
    "        \n",
    "    # img = filters.sobel(img)\n",
    "    \n",
    "    return img\n",
    "        \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_circles(circle_array):\n",
    "    # print(circle_array)\n",
    "    # Convert the array to a NumPy array\n",
    "    \n",
    "    # Find unique center coordinates\n",
    "    unique_centers, unique_indices = np.unique(circle_array[:, :2], axis=0, return_index=True)\n",
    "    # print(unique_indices)\n",
    "    \n",
    "    # Get the indices of circles with largest radius for each unique center\n",
    "    largest_circles = []\n",
    "    for center in unique_centers:\n",
    "      largest_circle = np.array((center[0], center[1], 0))\n",
    "      for j in range(len(circle_array)):\n",
    "        circle = circle_array[j]\n",
    "        if (circle[0] == center[0] and circle[1]==center[1] and circle[2] > largest_circle[2]):\n",
    "          largest_circle[2] = circle[2] \n",
    "      largest_circles.append(largest_circle)\n",
    "  \n",
    "    # print(largest_circles)\n",
    "               \n",
    "      \n",
    "\n",
    "    # # Convert the list of indices to a NumPy array\n",
    "    # max_radius_indices = np.array(max_radius_indices)\n",
    "    # print(max_radius_indices)\n",
    "    \n",
    "    return np.array(largest_circles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the input is a cv image so x and y are swapped\n",
    "def extract_circles_images(x, y, r, img, down):\n",
    "    factor = r + 10\n",
    "    left = (x - factor)*down\n",
    "    right = (x + factor)*down\n",
    "    up = (y - factor)*down\n",
    "    bottom = (y + factor)*down\n",
    "    output = img.copy()\n",
    "    output[:, :, 0] = img[:, :, 2]\n",
    "    output[:, :, 2] = img[:, :, 0]\n",
    "    return output[up:bottom, left:right, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_circles(path, debug = False):\n",
    "    img = cv.imread(path)\n",
    "    full_size_img = img.copy()\n",
    "    down = 3\n",
    "    size = (int(img.shape[1]/down), int(img.shape[0]/down))\n",
    "    img = cv.resize(img, size, interpolation=cv.INTER_LINEAR)\n",
    "\n",
    "    output = img.copy()\n",
    "    output[:, :, 0] = img[:, :, 2]\n",
    "    output[:, :, 2] = img[:, :, 0]\n",
    "    img[:, :, 2] = 0\n",
    "\n",
    "    gray = cv.blur(cv.cvtColor(img, cv.COLOR_BGR2GRAY), (8, 8))\n",
    "\n",
    "    # detect circles in the image\n",
    "    circles = cv.HoughCircles(gray, cv.HOUGH_GRADIENT_ALT, dp=1, minDist = 50, minRadius=50, maxRadius=200, param1=5, param2=0.6)\n",
    "    # ensure at least some circles were found\n",
    "    circles_imgs = []\n",
    "    if circles is not None:\n",
    "    # convert the (x, y) coordinates and radius of the circles to integers\n",
    "        circles = np.round(circles[0, :]).astype(\"int\")\n",
    "        circles = filter_circles(circles)\n",
    "        print(f\"detected {len(circles)} circles\")\n",
    "    \n",
    "        for (x, y, r) in circles:\n",
    "            # print(x, y, r)\n",
    "            # draw the circle in the output image, then draw a rectangle\n",
    "                # corresponding to the center of the circle\n",
    "            cv.circle(output, (x, y), r, (0, 255, 0), 4)\n",
    "            cv.rectangle(output, (x - 5, y - 5), (x + 5, y + 5), (0, 255, 0), -1)\n",
    "            new_circle = extract_circles_images(x, y, r, full_size_img, down)\n",
    "            circles_imgs.append(new_circle)\n",
    "            if debug:\n",
    "                plt.imshow(new_circle)\n",
    "                plt.show()\n",
    "            # circles_imgs.append(extract_circles_images(x, y, r, output))\n",
    "    \n",
    "        # show the output image\n",
    "    if debug:\n",
    "        plt.imshow(output)\n",
    "        plt.show()\n",
    "    return circles_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_data_paths():\n",
    "    training_paths = []\n",
    "    base_dir = \"./data/train/\"\n",
    "    for d in os.listdir(base_dir):\n",
    "        training_dir = f\"{base_dir}/{d}\"\n",
    "        for path in os.listdir(training_dir):\n",
    "            file_path = f\"{training_dir}/{path}\"\n",
    "            training_paths.append(file_path)\n",
    "            # print(file_path)\n",
    "    return training_paths\n",
    "        \n",
    "# get_training_data_paths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_for_image(path):\n",
    "    filename = path.split(\"/\")[-1].split(\".\")[0]\n",
    "\n",
    "    data = np.genfromtxt('./data/train_labels.csv', delimiter=',', dtype=str)\n",
    "\n",
    "# Assume the first column contains the strings you want to search through\n",
    "    first_column = data[:, 0]\n",
    "\n",
    "    # Find the index of the first entry that matches your string\n",
    "    index = np.where(first_column == filename)[0]\n",
    "    \n",
    "    if index.size > 0:\n",
    "        # print(f\"The first entry matching '{filename}' is at index {index[0]}.\")\n",
    "        #we add 0 in order to account for non coins\n",
    "        label_vector = np.append(data[index[0]][1:], 0)\n",
    "        # print(label_vector)\n",
    "        return torch.from_numpy(label_vector.astype(np.float32))\n",
    "        # You can access the corresponding row using data[index[0]]\n",
    "    else:\n",
    "        # print(f\"No entry matching '{filename}' found.\")\n",
    "        return torch.zeros(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = \"./data/train/1. neutral_bg//\"\n",
    "# d = \"./data/train/2. noisy_bg///\"\n",
    "# d = \"./data/train/3. hand///\"\n",
    "d = \"./data/train/5. noisy_bg_outliers/\"\n",
    "# d = \"./data/train/6. hand_outliers///\"\n",
    "# d = \"./data/test//\"\n",
    "# for f in os.listdir(d):\n",
    "\n",
    "paths = get_training_data_paths()\n",
    "p = paths[0]\n",
    "if get_label_for_image(p).shape[0] == 0:\n",
    "    print(\"wrong filename\")\n",
    "\n",
    "circles = find_circles(paths[0], debug=True)\n",
    "# for path in get_training_data_paths():\n",
    "# img = cv.imread(f\"{d}/{f}\")[::3, ::3].astype(np.uint8)\n",
    "# img[:, :, 1] = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f'Using {device} for inference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet152', pretrained=True)\n",
    "resnet152 = torchvision.models.resnet152(weights=torchvision.models.ResNet152_Weights.IMAGENET1K_V2).to(device)\n",
    "def extract_features(input_image):\n",
    "    # or any of these variants\n",
    "    # model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet34', pretrained=True)\n",
    "    # model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=True)\n",
    "    # model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet101', pretrained=True)\n",
    "    # model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet152', pretrained=True)\n",
    "    resnet152.eval()\n",
    "    feature_extractor = torch.nn.Sequential(*list(resnet152.children())[:-1])\n",
    "\n",
    "    image_dim = torch.tensor([input_image.shape[0]]).to(device)\n",
    "    # print(image_dim)\n",
    "\n",
    "    input_image = Image.fromarray(input_image)\n",
    "    # input_image.show()\n",
    "    preprocess = transforms.Compose([\n",
    "        # transforms.Resize(256),\n",
    "        transforms.CenterCrop(850),\n",
    "        transforms.ToTensor(),\n",
    "        # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    input_tensor = preprocess(input_image)\n",
    "    \n",
    "    # plt.imshow(input_tensor.permute(1, 2, 0))\n",
    "    # plt.show()\n",
    "    \n",
    "    input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
    "\n",
    "    # move the input and model to GPU for speed if available\n",
    "\n",
    "    input_batch = input_batch.to(device)\n",
    "    feature_extractor.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        features = feature_extractor(input_batch)\n",
    "    # Tensor of shape 1000, with confidence scores over ImageNet's 1000 classes\n",
    "    # print(output[0])\n",
    "    # The output has unnormalized scores. To get probabilities, you can run a softmax on it.\n",
    "    # probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
    "    features = torch.flatten(features)\n",
    "    # features = torch.cat((features, image_dim))\n",
    "\n",
    "    # print(features.size())\n",
    "    return features\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 1: Load a pre-trained ViT model\n",
    "# vit = vit_b_16(weights=ViT_B_16_Weights.IMAGENET1K_V1).to(device)\n",
    "# # model = timm.create_model('vit_base_patch16_224', pretrained=True,  ViT_B_16_Weights.IMAGENET1K_V1:)\n",
    "\n",
    "# # Step 2: Modify the model to be a feature extractor\n",
    "# # Remove the classification head\n",
    "# vit.head = nn.Identity()\n",
    "# def extract_features_vit(input_image):\n",
    "\n",
    "#     # Set the model to evaluation mode\n",
    "#     vit.eval()\n",
    "\n",
    "#     # Step 3: Define the transformation pipeline\n",
    "#     transform = transforms.Compose([\n",
    "#         transforms.Resize((224, 224)),\n",
    "#         transforms.ToTensor(),\n",
    "#         # transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n",
    "#         # transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n",
    "#     ])\n",
    "\n",
    "#     # Step 4: Load an image and preprocess it\n",
    "#     # image_path = get_training_data_paths()[0]\n",
    "#     # image_path = 'path_to_your_image.jpg'  # Replace with your image path\n",
    "#     image = Image.fromarray(input_image)\n",
    "    \n",
    "#     # image = Image.open(image_path)\n",
    "#     image = transform(image).to(device)\n",
    "#     # display_image = (image.permute(1, 2, 0)*255).int()\n",
    "#     # print(display_image)\n",
    "#     # plt.imshow(display_image)\n",
    "#     # plt.show()\n",
    "    \n",
    "#     image = image.unsqueeze(0)  # Add batch dimension\n",
    "#     feats = vit._process_input(image)\n",
    "#     # Step 5: Extract features\n",
    "#     with torch.no_grad():\n",
    "#         # features = vit(image)\n",
    "#         batch_class_token = vit.class_token.expand(image.shape[0], -1, -1)\n",
    "#         feats = torch.cat([batch_class_token, feats], dim=1)\n",
    "\n",
    "#         feats = vit.encoder(feats)\n",
    "\n",
    "#         # We're only interested in the representation of the CLS token that we appended at position 0\n",
    "#         feats = feats[:, 0]\n",
    "\n",
    "#         # print(feats.shape)\n",
    "#         return feats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for circle in circles:\n",
    "    print(extract_features(circle).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_data_paths():\n",
    "    test_paths = []\n",
    "    base_dir = \"./data/test/\"\n",
    "    for path in os.listdir(base_dir):\n",
    "        file_path = f\"{base_dir}/{path}\"\n",
    "        test_paths.append(file_path)\n",
    "            # print(file_path)\n",
    "    return test_paths\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training on individual coin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = torch.nn.Sequential( \n",
    "    torch.nn.Linear(in_features = 2048, out_features = 512), \n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(in_features = 512, out_features = 17), \n",
    "    # torch.nn.ReLU(),\n",
    "    # torch.nn.Linear(in_features = 256, out_features = 17), \n",
    "    # torch.nn.Softmax(dim=1) \n",
    ")\n",
    "\n",
    "linear = linear.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"chf_5\", \"chf_2\", \"chf_1\", \"chf_0.5\", \"chf_0.2\", \"chf_0.1\", \"chf_0.05\", \"eur_2\", \"eur_1\", \"eur_0.5\", \"eur_0.2\", \"eur_0.1\", \"eur_0.05\", \"eur_0.02\", \"eur_0.01\", \"OOD\", \"bg\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_set_size():\n",
    "    size = 0\n",
    "    for index, c in enumerate(class_names):\n",
    "        labeled_coins_dir = \"./data/labeled_coins/\"\n",
    "        selected_dir = f\"{labeled_coins_dir}{c}\"\n",
    "        files = os.listdir(selected_dir)\n",
    "        size += len(files)\n",
    "    return size\n",
    "\n",
    "print(get_training_set_size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from PIL import Image as im \n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss() \n",
    "optimizer = torch.optim.Adam(linear.parameters(), lr=5e-4)\n",
    "\n",
    "data_set_size = get_training_set_size()\n",
    "\n",
    "trainX = torch.zeros((data_set_size, 2048)).to(device)\n",
    "trainY = torch.zeros(data_set_size).to(device)\n",
    "\n",
    "data_index = 0\n",
    "\n",
    "\n",
    "\n",
    "for index, c in enumerate(class_names):\n",
    "    print(f\"extracting class {index}\")\n",
    "    labeled_coins_dir = \"./data/labeled_coins/\"\n",
    "    selected_dir = f\"{labeled_coins_dir}{c}\"\n",
    "    files = os.listdir(selected_dir)\n",
    "    for j, file in enumerate(files):\n",
    "        target = torch.tensor([index]).to(device)\n",
    "\n",
    "        selected_file_path = f\"{selected_dir}/{file}\"\n",
    "        coin = im.open(selected_file_path)\n",
    "        # degrees = random.randint(0, 360)\n",
    "        # coin = coin.rotate(degrees, resample=Image.BICUBIC)\n",
    "    #     # coin.show()\n",
    "        \n",
    "    #     \"\"\"\n",
    "    #     extracting features + training\n",
    "    #     \"\"\"\n",
    "\n",
    "    #     optimizer.zero_grad()\n",
    "        x = extract_features(np.array(coin))\n",
    "        trainX[data_index] = x\n",
    "        trainY[data_index] = index\n",
    "\n",
    "        \n",
    "        data_index += 1\n",
    "\n",
    "nb_epochs = 1000\n",
    "\n",
    "for epoch in range(nb_epochs):\n",
    "    optimizer.zero_grad()\n",
    "            \n",
    "    pred = linear(trainX)\n",
    "    # print(pred.shape)\n",
    "    loss = criterion(pred, trainY.to(device).long()) \n",
    "    loss.backward() \n",
    "    # print(f\"loss at epoch {epoch} - {loss}\")\n",
    "    # if epoch %1 == 0:\n",
    "    print(f\"loss at {epoch} - {loss}\")\n",
    "    optimizer.step() \n",
    "        \n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "    #     x = torch.unsqueeze(x, 0)\n",
    "        \n",
    "    #     selected_file = random.choice(files)\n",
    "\n",
    "#update after each sample\n",
    "# for i in range(5000):\n",
    "    \n",
    "#     \"\"\"\n",
    "#     Selecting image at random\n",
    "#     \"\"\"\n",
    "#     index = np.random.randint(0, 17)\n",
    "#     class_nb = len(class_names)\n",
    "#     # target = torch.zeros(class_nb).to(device)\n",
    "#     # target[index] = 1\n",
    "#     target = torch.tensor([index]).to(device)\n",
    "#     # target[0] = index\n",
    "    \n",
    "\n",
    "#     labeled_coins_dir = \"./data/labeled_coins/\"\n",
    "#     selected_dir = f\"{labeled_coins_dir}{class_names[index]}\"\n",
    "#     files = os.listdir(selected_dir)\n",
    "#     selected_file = random.choice(files)\n",
    "#     selected_file_path = f\"{selected_dir}/{selected_file}\"\n",
    "#     # print(selected_file_path)\n",
    "    \n",
    "#     coin = im.open(selected_file_path)\n",
    "#     degrees = random.randint(0, 360)\n",
    "#     coin = coin.rotate(degrees, resample=Image.BICUBIC)\n",
    "#     # coin.show()\n",
    "    \n",
    "#     \"\"\"\n",
    "#     extracting features + training\n",
    "#     \"\"\"\n",
    "\n",
    "#     optimizer.zero_grad()\n",
    "#     x = extract_features_vit(np.array(coin))\n",
    "#     # x = torch.unsqueeze(x, 0)\n",
    "\n",
    "#     pred = linear(x)\n",
    "#     # print(pred)\n",
    "#     # print(target)\n",
    "#     loss = criterion(pred, target) \n",
    "#     loss.backward() \n",
    "#     if i %10 == 0:\n",
    "#         print(f\"loss at {i} - {loss}\")\n",
    "#     optimizer.step() \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainX.shape)\n",
    "print(trainY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_header = \"id,5CHF,2CHF,1CHF,0.5CHF,0.2CHF,0.1CHF,0.05CHF,2EUR,1EUR,0.5EUR,0.2EUR,0.1EUR,0.05EUR,0.02EUR,0.01EUR,OOD\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_to_filename(path):\n",
    "    return path.split(\"/\")[-1].split(\".\")[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_radius(coin, min_radius, max_radius, debug=False):\n",
    "    img = (rgb2gray(coin)*255).astype(np.uint8)\n",
    "    img = cv.blur(img, (16, 16))[::3, ::3]\n",
    "    \n",
    "    min_r = int((min_radius*0.9)//3)\n",
    "    max_r = int((max_radius*1.1)//3)\n",
    "    \n",
    "    circle = cv.HoughCircles(img, cv.HOUGH_GRADIENT_ALT, dp=1, minDist = 50, minRadius=min_r, maxRadius=max_r, param1=50, param2=0.6)\n",
    "    # print(circle)\n",
    "    \n",
    "    if circle is not None:\n",
    "# convert the (x, y) coordinates and radius of the circles to integers\n",
    "        circles = np.round(circle[0, :]).astype(\"int\")\n",
    "        circles = filter_circles(circles)\n",
    "        # print(f\"detected {len(circles)} circles\")\n",
    "    \n",
    "        for (x, y, r) in circles:\n",
    "            # print(x, y, r)\n",
    "            # draw the circle in the output image, then draw a rectangle\n",
    "                # corresponding to the center of the circle\n",
    "            radius = 3*r\n",
    "            if debug:\n",
    "                # print()\n",
    "                cv.circle(coin, (3*x, 3*y), 3*r, (0, 255, 0), 4)\n",
    "                plt.title(f\"radius: {radius}\")\n",
    "                plt.imshow(coin)\n",
    "                plt.show()\n",
    "            return radius\n",
    "    else:\n",
    "        if debug:\n",
    "            print(\"no circle found\")\n",
    "        return 0\n",
    "            # new_circle = extract_circles_images(x, y, r, full_size_img, down)\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_chf_cents(coin, pred_class):\n",
    "    cents_20_radius = 250\n",
    "    cents_10_radius = 228\n",
    "    cents_50_radius = 208\n",
    "    factor = 0.05\n",
    "    \n",
    "    radius = find_radius(coin, min_radius=cents_50_radius, max_radius=cents_10_radius, debug=True)\n",
    "    if radius < 150: return pred_class\n",
    "        \n",
    "    values = np.array((cents_50_radius, cents_20_radius, cents_10_radius))\n",
    "    classes = [3, 4, 5]\n",
    "    pred = classes[np.argmin(np.abs(values - radius))]\n",
    "    print(f\"returning {class_names[pred]}\")\n",
    "    return pred\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    # #if radius too small\n",
    "    # if radius < (1 - factor)*cents_50_radius: \n",
    "    #     print(f\"returning {class_names[pred_class]}\")\n",
    "        \n",
    "    #     return pred_class\n",
    "    \n",
    "    # ## we detect 0.50_chf\n",
    "    # if radius > (1 - factor)*cents_50_radius and radius < (1 + factor)*cents_50_radius:\n",
    "    #     print(f\"returning {class_names[3]}\")\n",
    "    #     return 3\n",
    "    \n",
    "    # ## we detect 0.1_chf\n",
    "    # if radius > (1 - factor)*cents_10_radius and radius < (1 + factor)*cents_10_radius:\n",
    "    #     print(f\"returning {class_names[5]}\")\n",
    "    #     return 5\n",
    "    \n",
    "    # ## we detect 0.2_chf\n",
    "    # if radius > (1 - factor)*cents_20_radius and radius < (1 + factor)*cents_20_radius:\n",
    "    #     print(f\"returning {class_names[4]}\")\n",
    "    #     return 4\n",
    "    \n",
    "    # return pred_class\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_chf_francs(coin, pred_class):\n",
    "    francs_2_radius = 315\n",
    "    francs_1_radius = 265\n",
    "    \n",
    "    radius = find_radius(coin, min_radius=francs_1_radius, max_radius=francs_2_radius, debug=False)\n",
    "    if radius < 240: return pred_class\n",
    "        \n",
    "    values = np.array((francs_2_radius, francs_1_radius))\n",
    "    classes = [1, 2]\n",
    "    pred = classes[np.argmin(np.abs(values - radius))]\n",
    "    print(f\"returning {class_names[pred]} - before {class_names[pred_class]}\")\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_eur_cents(coin, pred_class):\n",
    "    cents_1_radius = 192\n",
    "    cents_2_radius = 222\n",
    "    cents_5_radius = 249\n",
    "    \n",
    "    \n",
    "    \n",
    "    radius = find_radius(coin, min_radius=cents_1_radius, max_radius=cents_5_radius, debug=False)\n",
    "    if radius < 170: return pred_class\n",
    "        \n",
    "    values = np.array((cents_5_radius, cents_2_radius, cents_1_radius))\n",
    "    classes = [12, 13, 14]\n",
    "    pred = classes[np.argmin(np.abs(values - radius))]\n",
    "    print(f\"returning {class_names[pred]} - before {class_names[pred_class]}\")\n",
    "    return pred\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_eur_cents_10_20(coin, pred_class):\n",
    "    cents_10_radius = 250\n",
    "    cents_20_radius = 222\n",
    "    \n",
    "    \n",
    "    \n",
    "    radius = find_radius(coin, min_radius=cents_10_radius, max_radius=cents_20_radius, debug=True)\n",
    "    if radius < 200: return pred_class\n",
    "        \n",
    "    values = np.array((cents_20_radius, cents_10_radius))\n",
    "    classes = [10, 11]\n",
    "    pred = classes[np.argmin(np.abs(values - radius))]\n",
    "    print(f\"returning {class_names[pred]} - before {class_names[pred_class]}\")\n",
    "    return pred\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.random.randint(0, 17)\n",
    "csv_file = csv_header\n",
    "csv_file += \"\\n\"\n",
    "with torch.no_grad():\n",
    "# index = 16\n",
    "    linear.eval()\n",
    "\n",
    "    # labeled_coins_dir = \"./data/labeled_coins/\"\n",
    "    # selected_dir = f\"{labeled_coins_dir}{class_names[index]}\"\n",
    "    # files = os.listdir(selected_dir)\n",
    "    # selected_file = random.choice(files)\n",
    "    # selected_file_path = f\"{selected_dir}/{selected_file}\"\n",
    "    # print(selected_file_path)\n",
    "    test_index = 17\n",
    "\n",
    "    for i, path in enumerate(get_test_data_paths()):\n",
    "        print(path)\n",
    "    \n",
    "        # path = \"./data/test/L0000113.JPG\"\n",
    "        coins = find_circles(path)\n",
    "        # coins = find_circles(\"./data/train/1. neutral_bg/L1010277.JPG\")\n",
    "        \n",
    "        p = np.zeros(16, dtype=np.uint8)\n",
    "        for coin in coins:\n",
    "            shape = coin.shape\n",
    "            if shape[0] <10 or shape[1]<10: continue\n",
    "            # print(coin.shape)\n",
    "        \n",
    "            \n",
    "            \n",
    "            # coin = np.array(im.open(selected_file_path))\n",
    "            # coin.show()\n",
    "\n",
    "\n",
    "            x = extract_features(coin).to(device)\n",
    "            # print(x)\n",
    "            x = torch.unsqueeze(x, 0)\n",
    "\n",
    "            pred_test = linear(x).flatten()\n",
    "            pred_class = torch.argmax(pred_test)\n",
    "            \n",
    "           \n",
    "            \n",
    "            \n",
    "            proba = (torch.softmax(pred_test, dim=0)*100)\n",
    "            max_proba = torch.max(proba)\n",
    "            # print(max_proba)\n",
    "            # plt.title(class_names[pred_class.item()])\n",
    "            # plt.imshow(coin)\n",
    "            # plt.show()\n",
    "            if pred_class == 16: continue\n",
    "            \n",
    "            # if max_proba < 0.7:\n",
    "            \n",
    "            # if pred_class==3 or pred_class == 4 or pred_class == 5:\n",
    "            #     # print(\"checking chf cents\")\n",
    "            #     pred_class = test_chf_cents(coin, pred_class.item())\n",
    "                \n",
    "            if pred_class == 12 or pred_class == 13 or pred_class == 14:\n",
    "                # print(\"checking eur cents\")\n",
    "                \n",
    "                pred_class = test_eur_cents(coin, pred_class.item())\n",
    "            \n",
    "            elif pred_class == 1 or pred_class == 2:\n",
    "                # print(\"checking chf francs\")\n",
    "                \n",
    "                pred_class = test_chf_francs(coin, pred_class.item())\n",
    "            \n",
    "            # if pred_class == 4 or pred_class==5:\n",
    "            #     radius = find_radius(coin)\n",
    "            #     print(f\"radius: {radius}\")\n",
    "            #     if radius != 0:\n",
    "            #         if radius < 235:\n",
    "            #             pred_class = 4\n",
    "            #         elif radius < 220:\n",
    "            #             pred_class = 6\n",
    "            #         else: pred_calss = 5\n",
    "                \n",
    "            # print(pred_class)\n",
    "            \n",
    "            p[pred_class] += 1\n",
    "        # print(f\"pred {pred_class}\")\n",
    "        # print(f\"target: {index}\")\n",
    "        \n",
    "        # print(p)\n",
    "        p_string = np.array2string(p, separator=', ', precision=0).replace(\"[\", \"\").replace(\"]\", \"\")\n",
    "        csv_row = f\"{path_to_filename(path)},{p_string}\"\n",
    "        print(csv_row)\n",
    "        # print(csv_row)\n",
    "        csv_file += csv_row\n",
    "        csv_file += \"\\n\"\n",
    "\n",
    "with open('./data/submission.csv', 'w') as file:\n",
    "    # Write a string to the file\n",
    "    file.write(csv_file)\n",
    "    \n",
    "# print(csv_row)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extracting all coins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image as im \n",
    "paths = get_training_data_paths()\n",
    "print(len(paths))\n",
    "\n",
    "# for path in paths:\n",
    "for path in paths:\n",
    "    circles =find_circles(path)\n",
    "    for i, circle in enumerate(circles):\n",
    "        file_number = path.split(\"/\")[-1].split(\".\")[0]\n",
    "        print(file_number)\n",
    "        im.fromarray(circle).save(f\"./data/unlabeled_coins/{file_number}_{i}.jpg\")\n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### label hd coins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dir = \"./data/hd_coins/\"\n",
    "source_dir = \"./data/labeled_coins/\"\n",
    "unlabeled_dir = \"./data/unlabeled_coins/\"\n",
    "for d in os.listdir(source_dir):\n",
    "    class_dir = target_dir + d\n",
    "    if not os.path.exists(class_dir):\n",
    "        os.mkdir(class_dir)\n",
    "    \n",
    "    for file in os.listdir(source_dir+d):\n",
    "        src_file = unlabeled_dir+file\n",
    "        dst_file = target_dir + d+\"/\"+file\n",
    "        os.rename(src_file, dst_file)\n",
    "        # print(dst_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compute area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coins_dir = \"./data/labeled_coins/\"\n",
    "\n",
    "# radius_list = []\n",
    "\n",
    "# for d in os.listdir(coins_dir):\n",
    "#     if d == \"bg\": continue\n",
    "    \n",
    "#     class_dir = coins_dir +d +\"/\"\n",
    "#     print(class_dir)\n",
    "\n",
    "path = get_test_data_paths()[5]\n",
    "\n",
    "# for path in os.listdir(class_dir):\n",
    "    \n",
    "#     img = cv.imread(class_dir+path, cv.IMREAD_GRAYSCALE)\n",
    "#     # plt.imshow(img, cmap=\"gray\")\n",
    "#     # plt.show()\n",
    "#     # print(path)\n",
    "    \n",
    "coins = find_circles(path)\n",
    "\n",
    "\n",
    "for coin in coins:\n",
    "        print(find_radius(coin))\n",
    "   \n",
    "        # pass\n",
    "# print(f\"radius for {d} - {np.mean(radius_list)}\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io, color, filters, morphology, measure\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.segmentation import watershed\n",
    "from scipy import ndimage as ndi\n",
    "\n",
    "def detect_coins(image):\n",
    "    # Load the image\n",
    "    # image = io.imread(image_path)\n",
    "    # if image is None:\n",
    "    #     raise FileNotFoundError(f\"Image not found: {image_path}\")\n",
    "\n",
    "    # # Convert to grayscale\n",
    "    gray = (color.rgb2gray(image)*255).astype(np.uint8)\n",
    "\n",
    "    # Apply Gaussian filter to smooth the image\n",
    "    blurred = filters.gaussian(gray, sigma=2.0)\n",
    "\n",
    "    # Apply Otsu's thresholding\n",
    "    thresh = filters.threshold_otsu(blurred)\n",
    "    binary = blurred < thresh\n",
    "\n",
    "    # Remove small objects\n",
    "    cleaned = morphology.remove_small_objects(binary, 50)\n",
    "\n",
    "    # Compute the distance transform\n",
    "    distance = ndi.distance_transform_edt(cleaned)\n",
    "\n",
    "    # Find local maxima\n",
    "    local_maxi = peak_local_max(distance, footprint=np.ones((3, 3)), labels=cleaned)\n",
    "\n",
    "    # Perform connected component labeling\n",
    "    markers = measure.label(local_maxi)\n",
    "\n",
    "    # Apply watershed algorithm\n",
    "    labels = watershed(-distance, markers, mask=cleaned)\n",
    "\n",
    "    # Plot the result\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax.imshow(image, cmap=plt.cm.gray)\n",
    "    for region in measure.regionprops(labels):\n",
    "        # Draw rectangle around segmented coins\n",
    "        minr, minc, maxr, maxc = region.bbox\n",
    "        rect = plt.Rectangle((minc, minr), maxc - minc, maxr - minr,\n",
    "                             fill=False, edgecolor='red', linewidth=2)\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "    ax.set_title('Detected Coins')\n",
    "    ax.set_axis_off()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "# detect_coins('coins.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ball_array(radius):\n",
    "    \"\"\"\n",
    "    Create a 2D numpy array representing a circle.\n",
    "    \n",
    "    Parameters:\n",
    "        radius (int): Radius of the circle.\n",
    "        \n",
    "    Returns:\n",
    "        numpy.ndarray: 2D numpy array representing the circle.\n",
    "    \"\"\"\n",
    "    # Create an empty 2D numpy array with dimensions (2*radius, 2*radius)\n",
    "    circle = np.zeros((2 * radius, 2 * radius), dtype=np.uint8)\n",
    "    \n",
    "    # Generate coordinates of the circle's center\n",
    "    center_x, center_y = radius, radius\n",
    "    \n",
    "    # Fill the array with values representing the circle\n",
    "    for x in range(2 * radius):\n",
    "        for y in range(2 * radius):\n",
    "            if (x - center_x) ** 2 + (y - center_y) ** 2 <= radius ** 2:\n",
    "                circle[x, y] = 1\n",
    "    \n",
    "    return circle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# img = loadImageOfType(ImageType.NOISY, downsample=8, grayscale=True)\n",
    "from skimage.morphology import closing\n",
    "d = \"./data/train/2. noisy_bg////\"\n",
    "\n",
    "R_chf = 178\n",
    "G_chf = 161\n",
    "B_chf = 141\n",
    "\n",
    "\n",
    "for path in os.listdir(d)[0:10]:\n",
    "\n",
    "    # path = os.listdir(d)[2]\n",
    "    file_path = d + path\n",
    "    coins = find_circles(file_path)\n",
    "    for coin in coins:\n",
    "        print(find_radius(coin))\n",
    "               \n",
    "\n",
    "        # print(img)\n",
    "        # t = 20\n",
    "        \n",
    "        # mask = (coin[:, :, 0] < R_chf +t) & (coin[:, :, 0] > R_chf - t) & (coin[:, :, 1] < G_chf +t) & (coin[:, :, 1] > G_chf - t)& (coin[:, :, 2] < B_chf +t/2) & (coin[:, :, 2] > B_chf - t)\n",
    "        # thresh = np.zeros((coin.shape[0], coin.shape[1]))\n",
    "        \n",
    "        # thresh[mask] = 1\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        # plotHistogram(img)\n",
    "\n",
    "        # elevation_map = filters.sobel(img)\n",
    "        # markers = np.zeros_like(img)\n",
    "        # # markers[img < 150] = 2\n",
    "        # # markers[img > 180] = 1\n",
    "        # markers[img < 150] = 1\n",
    "        # markers[img > 220] = 2\n",
    "        # segmentation_coins = (segmentation.watershed(elevation_map, markers) - 1).astype(bool)\n",
    "        # segmentation_coins = closing(segmentation_coins, create_ball_array(img.shape[0]//4))\n",
    "        # pixel_nb = np.sum(segmentation_coins.astype(np.uint8))\n",
    "        # radius = np.sqrt(pixel_nb/(np.pi))\n",
    "        # print(radius)\n",
    "        \n",
    "        # plt.imshow(coin)\n",
    "        # plt.show()\n",
    "\n",
    "\n",
    "        # fig, axs = plt.subplots(1, 2)\n",
    "        # fig.set_size_inches(15, 10)\n",
    "        # axs[0].imshow(coin, cmap=\"gray\")\n",
    "        # # axs[1].imshow(segmentation_coins, cmap=\"gray\")\n",
    "        # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = open('./data/submission.csv', 'r')\n",
    "lines = file1.readlines()\n",
    "file2 = open('./data/submission_eur_cents_chf_francs.csv', 'r')\n",
    "lines2 = file2.readlines()\n",
    "\n",
    "diff = 0\n",
    "for i in range(len(lines2)):\n",
    "    if lines[i] != lines2[i]:\n",
    "        diff+=1\n",
    "        print(lines[i], lines2[i])\n",
    "print(diff)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iapr_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
