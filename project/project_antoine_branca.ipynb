{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy\n",
    "!pip install matplotlib\n",
    "!pip install scikit-image\n",
    "!pip install pillow\n",
    "!pip install opencv-python\n",
    "!pip install timm\n",
    "!pip install tqdm\n",
    "# Check is at least python 3.9\n",
    "import sys \n",
    "assert (sys.version_info.major == 3) and (sys.version_info.minor == 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from typing import Callable\n",
    "import os\n",
    "from datetime import datetime\n",
    "from enum import Enum\n",
    "import random\n",
    "from skimage.color import rgb2gray, rgb2hsv\n",
    "from skimage import filters\n",
    "from skimage import segmentation\n",
    "from skimage.morphology import remove_small_holes, remove_small_objects\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import timm\n",
    "import torchvision\n",
    "from torchvision.models.vision_transformer import vit_b_16\n",
    "from torchvision.models import ViT_B_16_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "\n",
    "# Get os name\n",
    "os_name = platform.system().lower()\n",
    "num_workers = 8\n",
    "\n",
    "# OS X\n",
    "if 'darwin' in os_name:\n",
    "    print(\"Detected OS X\")\n",
    "    %pip install torch==1.8.1 torchvision==0.9.1 torchaudio==0.8.1\n",
    "# Linux \n",
    "elif 'linux' in os_name:\n",
    "    print(\"Detected Linux\")\n",
    "    %pip install torch==1.8.1 torchvision==0.9.1 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "# Windows \n",
    "else:\n",
    "    print(\"Detected Windows\")\n",
    "    num_workers = 0  # Hard fix for Windows users\n",
    "    %pip install torch==1.12.0 torchvision==0.13 -f https://download.pytorch.org/whl/torch_stable.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageType(Enum):\n",
    "    NEUTRAL = \"1. neutral_bg\"\n",
    "    NOISY = \"2. noisy_bg\"\n",
    "    HAND = \"3. hand\"\n",
    "    NEUTRAL_OOD = \"4. neutral_bg_outliers\"\n",
    "    NOISY_OOD = \"5. noisy_bg_outliers\"\n",
    "    HAND_OOD = \"6. hand_outliers\"\n",
    "    \n",
    "def loadImageOfType(type: ImageType, downsample: int = 1, grayscale: bool = False):\n",
    "    # directory = f\"./data/train/{type}\"\n",
    "    directory = os.path.join(\".\", \"data\", \"train\", type.value)\n",
    "    images = os.listdir(directory)\n",
    "    img = np.array(Image.open(os.path.join(directory, random.choice(images)))) \n",
    "    if downsample > 1:\n",
    "        img = img[::downsample, ::downsample, :]\n",
    "    if grayscale:\n",
    "        img = (rgb2gray(img)*255).astype(np.uint8)\n",
    "        \n",
    "    # img = filters.sobel(img)\n",
    "    \n",
    "    return img\n",
    "        \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_circles(circle_array):\n",
    "    # print(circle_array)\n",
    "    # Convert the array to a NumPy array\n",
    "    \n",
    "    # Find unique center coordinates\n",
    "    unique_centers, unique_indices = np.unique(circle_array[:, :2], axis=0, return_index=True)\n",
    "    # print(unique_indices)\n",
    "    \n",
    "    # Get the indices of circles with largest radius for each unique center\n",
    "    largest_circles = []\n",
    "    for center in unique_centers:\n",
    "      largest_circle = np.array((center[0], center[1], 0))\n",
    "      for j in range(len(circle_array)):\n",
    "        circle = circle_array[j]\n",
    "        if (circle[0] == center[0] and circle[1]==center[1] and circle[2] > largest_circle[2]):\n",
    "          largest_circle[2] = circle[2] \n",
    "      largest_circles.append(largest_circle)\n",
    "  \n",
    "    # print(largest_circles)\n",
    "               \n",
    "      \n",
    "\n",
    "    # # Convert the list of indices to a NumPy array\n",
    "    # max_radius_indices = np.array(max_radius_indices)\n",
    "    # print(max_radius_indices)\n",
    "    \n",
    "    return np.array(largest_circles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the input is a cv image so x and y are swapped\n",
    "def extract_circles_images(x, y, r, img, down):\n",
    "    factor = r\n",
    "    left = (x - factor)*down\n",
    "    right = (x + factor)*down\n",
    "    up = (y - factor)*down\n",
    "    bottom = (y + factor)*down\n",
    "    output = img.copy()\n",
    "    output[:, :, 0] = img[:, :, 2]\n",
    "    output[:, :, 2] = img[:, :, 0]\n",
    "    return output[up:bottom, left:right, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_circles(path, debug = False):\n",
    "    img = cv.imread(path)\n",
    "    full_size_img = img.copy()\n",
    "    down = 3\n",
    "    size = (int(img.shape[1]/down), int(img.shape[0]/down))\n",
    "    img = cv.resize(img, size, interpolation=cv.INTER_LINEAR)\n",
    "\n",
    "    output = img.copy()\n",
    "    output[:, :, 0] = img[:, :, 2]\n",
    "    output[:, :, 2] = img[:, :, 0]\n",
    "    img[:, :, 2] = 0\n",
    "\n",
    "    gray = cv.blur(cv.cvtColor(img, cv.COLOR_BGR2GRAY), (8, 8))\n",
    "\n",
    "    # detect circles in the image\n",
    "    circles = cv.HoughCircles(gray, cv.HOUGH_GRADIENT_ALT, dp=1, minDist = 50, minRadius=50, maxRadius=200, param1=5, param2=0.6)\n",
    "    # ensure at least some circles were found\n",
    "    circles_imgs = []\n",
    "    if circles is not None:\n",
    "    # convert the (x, y) coordinates and radius of the circles to integers\n",
    "        circles = np.round(circles[0, :]).astype(\"int\")\n",
    "        circles = filter_circles(circles)\n",
    "        print(f\"detected {len(circles)} circles\")\n",
    "    \n",
    "        for (x, y, r) in circles:\n",
    "            # print(x, y, r)\n",
    "            # draw the circle in the output image, then draw a rectangle\n",
    "                # corresponding to the center of the circle\n",
    "            # cv.circle(output, (x, y), r, (0, 255, 0), 4)\n",
    "            # cv.rectangle(output, (x - 5, y - 5), (x + 5, y + 5), (0, 255, 0), -1)\n",
    "            new_circle = extract_circles_images(x, y, r, full_size_img, down)\n",
    "            circles_imgs.append(new_circle)\n",
    "            if debug:\n",
    "                plt.imshow(new_circle)\n",
    "                plt.show()\n",
    "            # circles_imgs.append(extract_circles_images(x, y, r, output))\n",
    "    \n",
    "        # show the output image\n",
    "    if debug:\n",
    "        plt.imshow(output)\n",
    "        plt.show()\n",
    "    return circles_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_data_paths():\n",
    "    training_paths = []\n",
    "    base_dir = \"./data/train/\"\n",
    "    for d in os.listdir(base_dir):\n",
    "        training_dir = f\"{base_dir}/{d}\"\n",
    "        for path in os.listdir(training_dir):\n",
    "            file_path = f\"{training_dir}/{path}\"\n",
    "            training_paths.append(file_path)\n",
    "            # print(file_path)\n",
    "    return training_paths\n",
    "        \n",
    "# get_training_data_paths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_for_image(path):\n",
    "    filename = path.split(\"/\")[-1].split(\".\")[0]\n",
    "\n",
    "    data = np.genfromtxt('./data/train_labels.csv', delimiter=',', dtype=str)\n",
    "\n",
    "# Assume the first column contains the strings you want to search through\n",
    "    first_column = data[:, 0]\n",
    "\n",
    "    # Find the index of the first entry that matches your string\n",
    "    index = np.where(first_column == filename)[0]\n",
    "    \n",
    "    if index.size > 0:\n",
    "        # print(f\"The first entry matching '{filename}' is at index {index[0]}.\")\n",
    "        #we add 0 in order to account for non coins\n",
    "        label_vector = np.append(data[index[0]][1:], 0)\n",
    "        # print(label_vector)\n",
    "        return torch.from_numpy(label_vector.astype(np.float32))\n",
    "        # You can access the corresponding row using data[index[0]]\n",
    "    else:\n",
    "        # print(f\"No entry matching '{filename}' found.\")\n",
    "        return torch.zeros(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = \"./data/train/1. neutral_bg//\"\n",
    "# d = \"./data/train/2. noisy_bg///\"\n",
    "# d = \"./data/train/3. hand///\"\n",
    "d = \"./data/train/5. noisy_bg_outliers/\"\n",
    "# d = \"./data/train/6. hand_outliers///\"\n",
    "# d = \"./data/test//\"\n",
    "# for f in os.listdir(d):\n",
    "\n",
    "paths = get_training_data_paths()\n",
    "p = paths[0]\n",
    "if get_label_for_image(p).shape[0] == 0:\n",
    "    print(\"wrong filename\")\n",
    "\n",
    "circles = find_circles(paths[0], debug=True)\n",
    "# for path in get_training_data_paths():\n",
    "# img = cv.imread(f\"{d}/{f}\")[::3, ::3].astype(np.uint8)\n",
    "# img[:, :, 1] = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f'Using {device} for inference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet152', pretrained=True)\n",
    "resnet152 = torchvision.models.resnet152(weights=torchvision.models.ResNet152_Weights.IMAGENET1K_V2).to(device)\n",
    "def extract_features(input_image):\n",
    "    # or any of these variants\n",
    "    # model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet34', pretrained=True)\n",
    "    # model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=True)\n",
    "    # model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet101', pretrained=True)\n",
    "    # model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet152', pretrained=True)\n",
    "    resnet152.eval()\n",
    "    feature_extractor = torch.nn.Sequential(*list(resnet152.children())[:-1])\n",
    "\n",
    "    image_dim = torch.tensor([input_image.shape[0]]).to(device)\n",
    "    # print(image_dim)\n",
    "\n",
    "    input_image = Image.fromarray(input_image)\n",
    "    # input_image.show()\n",
    "    preprocess = transforms.Compose([\n",
    "        # transforms.Resize(256),\n",
    "        # transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    input_tensor = preprocess(input_image)\n",
    "    input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
    "\n",
    "    # move the input and model to GPU for speed if available\n",
    "\n",
    "    input_batch = input_batch.to(device)\n",
    "    feature_extractor.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        features = feature_extractor(input_batch)\n",
    "    # Tensor of shape 1000, with confidence scores over ImageNet's 1000 classes\n",
    "    # print(output[0])\n",
    "    # The output has unnormalized scores. To get probabilities, you can run a softmax on it.\n",
    "    # probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
    "    features = torch.flatten(features)\n",
    "    features = torch.cat((features, image_dim))\n",
    "\n",
    "    # print(features.size())\n",
    "    return features\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 1: Load a pre-trained ViT model\n",
    "# vit = vit_b_16(weights=ViT_B_16_Weights.IMAGENET1K_V1).to(device)\n",
    "# # model = timm.create_model('vit_base_patch16_224', pretrained=True,  ViT_B_16_Weights.IMAGENET1K_V1:)\n",
    "\n",
    "# # Step 2: Modify the model to be a feature extractor\n",
    "# # Remove the classification head\n",
    "# vit.head = nn.Identity()\n",
    "# def extract_features_vit(input_image):\n",
    "\n",
    "#     # Set the model to evaluation mode\n",
    "#     vit.eval()\n",
    "\n",
    "#     # Step 3: Define the transformation pipeline\n",
    "#     transform = transforms.Compose([\n",
    "#         transforms.Resize((224, 224)),\n",
    "#         transforms.ToTensor(),\n",
    "#         # transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n",
    "#         # transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n",
    "#     ])\n",
    "\n",
    "#     # Step 4: Load an image and preprocess it\n",
    "#     # image_path = get_training_data_paths()[0]\n",
    "#     # image_path = 'path_to_your_image.jpg'  # Replace with your image path\n",
    "#     image = Image.fromarray(input_image)\n",
    "    \n",
    "#     # image = Image.open(image_path)\n",
    "#     image = transform(image).to(device)\n",
    "#     # display_image = (image.permute(1, 2, 0)*255).int()\n",
    "#     # print(display_image)\n",
    "#     # plt.imshow(display_image)\n",
    "#     # plt.show()\n",
    "    \n",
    "#     image = image.unsqueeze(0)  # Add batch dimension\n",
    "#     feats = vit._process_input(image)\n",
    "#     # Step 5: Extract features\n",
    "#     with torch.no_grad():\n",
    "#         # features = vit(image)\n",
    "#         batch_class_token = vit.class_token.expand(image.shape[0], -1, -1)\n",
    "#         feats = torch.cat([batch_class_token, feats], dim=1)\n",
    "\n",
    "#         feats = vit.encoder(feats)\n",
    "\n",
    "#         # We're only interested in the representation of the CLS token that we appended at position 0\n",
    "#         feats = feats[:, 0]\n",
    "\n",
    "#         # print(feats.shape)\n",
    "#         return feats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for circle in circles:\n",
    "    print(extract_features(circle).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_data_paths():\n",
    "    test_paths = []\n",
    "    base_dir = \"./data/test/\"\n",
    "    for path in os.listdir(base_dir):\n",
    "        file_path = f\"{base_dir}/{path}\"\n",
    "        test_paths.append(file_path)\n",
    "            # print(file_path)\n",
    "    return test_paths\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training on individual coin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = torch.nn.Sequential( \n",
    "    torch.nn.Linear(in_features = 2049, out_features = 512), \n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(in_features = 512, out_features = 17), \n",
    "    # torch.nn.ReLU(),\n",
    "    # torch.nn.Linear(in_features = 256, out_features = 17), \n",
    "    # torch.nn.Softmax(dim=1) \n",
    ")\n",
    "\n",
    "linear = linear.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"chf_5\", \"chf_2\", \"chf_1\", \"chf_0.5\", \"chf_0.2\", \"chf_0.1\", \"chf_0.05\", \"eur_2\", \"eur_1\", \"eur_0.5\", \"eur_0.2\", \"eur_0.1\", \"eur_0.05\", \"eur_0.02\", \"eur_0.01\", \"OOD\", \"bg\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_set_size():\n",
    "    size = 0\n",
    "    for index, c in enumerate(class_names):\n",
    "        labeled_coins_dir = \"./data/labeled_coins/\"\n",
    "        selected_dir = f\"{labeled_coins_dir}{c}\"\n",
    "        files = os.listdir(selected_dir)\n",
    "        size += len(files)\n",
    "    return size\n",
    "\n",
    "print(get_training_set_size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from PIL import Image as im \n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss() \n",
    "optimizer = torch.optim.Adam(linear.parameters(), lr=5e-4)\n",
    "\n",
    "data_set_size = get_training_set_size()\n",
    "\n",
    "trainX = torch.zeros((data_set_size, 2049)).to(device)\n",
    "trainY = torch.zeros(data_set_size).to(device)\n",
    "\n",
    "data_index = 0\n",
    "\n",
    "\n",
    "\n",
    "for index, c in enumerate(class_names):\n",
    "    print(f\"extracting class {index}\")\n",
    "    labeled_coins_dir = \"./data/labeled_coins/\"\n",
    "    selected_dir = f\"{labeled_coins_dir}{c}\"\n",
    "    files = os.listdir(selected_dir)\n",
    "    for j, file in enumerate(files):\n",
    "        target = torch.tensor([index]).to(device)\n",
    "\n",
    "        selected_file_path = f\"{selected_dir}/{file}\"\n",
    "        coin = im.open(selected_file_path)\n",
    "        # degrees = random.randint(0, 360)\n",
    "        # coin = coin.rotate(degrees, resample=Image.BICUBIC)\n",
    "    #     # coin.show()\n",
    "        \n",
    "    #     \"\"\"\n",
    "    #     extracting features + training\n",
    "    #     \"\"\"\n",
    "\n",
    "    #     optimizer.zero_grad()\n",
    "        x = extract_features(np.array(coin))\n",
    "        trainX[data_index] = x\n",
    "        trainY[data_index] = index\n",
    "\n",
    "        \n",
    "        data_index += 1\n",
    "\n",
    "nb_epochs = 1000\n",
    "\n",
    "for epoch in range(nb_epochs):\n",
    "    optimizer.zero_grad()\n",
    "            \n",
    "    pred = linear(trainX)\n",
    "    # print(pred.shape)\n",
    "    loss = criterion(pred, trainY.to(device).long()) \n",
    "    loss.backward() \n",
    "    # print(f\"loss at epoch {epoch} - {loss}\")\n",
    "    # if epoch %1 == 0:\n",
    "    print(f\"loss at {epoch} - {loss}\")\n",
    "    optimizer.step() \n",
    "        \n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "    #     x = torch.unsqueeze(x, 0)\n",
    "        \n",
    "    #     selected_file = random.choice(files)\n",
    "\n",
    "#update after each sample\n",
    "# for i in range(5000):\n",
    "    \n",
    "#     \"\"\"\n",
    "#     Selecting image at random\n",
    "#     \"\"\"\n",
    "#     index = np.random.randint(0, 17)\n",
    "#     class_nb = len(class_names)\n",
    "#     # target = torch.zeros(class_nb).to(device)\n",
    "#     # target[index] = 1\n",
    "#     target = torch.tensor([index]).to(device)\n",
    "#     # target[0] = index\n",
    "    \n",
    "\n",
    "#     labeled_coins_dir = \"./data/labeled_coins/\"\n",
    "#     selected_dir = f\"{labeled_coins_dir}{class_names[index]}\"\n",
    "#     files = os.listdir(selected_dir)\n",
    "#     selected_file = random.choice(files)\n",
    "#     selected_file_path = f\"{selected_dir}/{selected_file}\"\n",
    "#     # print(selected_file_path)\n",
    "    \n",
    "#     coin = im.open(selected_file_path)\n",
    "#     degrees = random.randint(0, 360)\n",
    "#     coin = coin.rotate(degrees, resample=Image.BICUBIC)\n",
    "#     # coin.show()\n",
    "    \n",
    "#     \"\"\"\n",
    "#     extracting features + training\n",
    "#     \"\"\"\n",
    "\n",
    "#     optimizer.zero_grad()\n",
    "#     x = extract_features_vit(np.array(coin))\n",
    "#     # x = torch.unsqueeze(x, 0)\n",
    "\n",
    "#     pred = linear(x)\n",
    "#     # print(pred)\n",
    "#     # print(target)\n",
    "#     loss = criterion(pred, target) \n",
    "#     loss.backward() \n",
    "#     if i %10 == 0:\n",
    "#         print(f\"loss at {i} - {loss}\")\n",
    "#     optimizer.step() \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainX.shape)\n",
    "print(trainY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_header = \"id,5CHF,2CHF,1CHF,0.5CHF,0.2CHF,0.1CHF,0.05CHF,2EUR,1EUR,0.5EUR,0.2EUR,0.1EUR,0.05EUR,0.02EUR,0.01EUR,OOD\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_to_filename(path):\n",
    "    return path.split(\"/\")[-1].split(\".\")[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.random.randint(0, 17)\n",
    "csv_file = csv_header\n",
    "csv_file += \"\\n\"\n",
    "with torch.no_grad():\n",
    "# index = 16\n",
    "    linear.eval()\n",
    "\n",
    "    # labeled_coins_dir = \"./data/labeled_coins/\"\n",
    "    # selected_dir = f\"{labeled_coins_dir}{class_names[index]}\"\n",
    "    # files = os.listdir(selected_dir)\n",
    "    # selected_file = random.choice(files)\n",
    "    # selected_file_path = f\"{selected_dir}/{selected_file}\"\n",
    "    # print(selected_file_path)\n",
    "\n",
    "    for i, path in enumerate(get_test_data_paths()):\n",
    "        print(i)\n",
    "    \n",
    "        # path = \"./data/test/L0000113.JPG\"\n",
    "        coins = find_circles(path)\n",
    "        # coins = find_circles(\"./data/train/1. neutral_bg/L1010277.JPG\")\n",
    "        \n",
    "        p = np.zeros(16, dtype=np.uint8)\n",
    "        for coin in coins:\n",
    "            shape = coin.shape\n",
    "            if shape[0] <10 or shape[1]<10: continue\n",
    "            # print(coin.shape)\n",
    "        \n",
    "            \n",
    "            \n",
    "            # coin = np.array(im.open(selected_file_path))\n",
    "            # coin.show()\n",
    "\n",
    "\n",
    "            x = extract_features(coin).to(device)\n",
    "            # print(x)\n",
    "            x = torch.unsqueeze(x, 0)\n",
    "\n",
    "            pred_test = linear(x).flatten()\n",
    "            # print(pred_test)\n",
    "            pred_class = torch.argmax(pred_test)\n",
    "            if pred_class == 16: continue\n",
    "            p[pred_class] += 1\n",
    "        # print(f\"pred {pred_class}\")\n",
    "        # print(f\"target: {index}\")\n",
    "        \n",
    "        # print(p)\n",
    "        p_string = np.array2string(p, separator=', ', precision=0).replace(\"[\", \"\").replace(\"]\", \"\")\n",
    "        csv_row = f\"{path_to_filename(path)},{p_string}\"\n",
    "        # print(csv_row)\n",
    "        csv_file += csv_row\n",
    "        csv_file += \"\\n\"\n",
    "\n",
    "with open('./data/submission.csv', 'w') as file:\n",
    "    # Write a string to the file\n",
    "    file.write(csv_file)\n",
    "    \n",
    "# print(csv_row)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extracting all coins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image as im \n",
    "paths = get_training_data_paths()\n",
    "print(len(paths))\n",
    "\n",
    "# for path in paths:\n",
    "for path in paths:\n",
    "    circles =find_circles(path)\n",
    "    for i, circle in enumerate(circles):\n",
    "        file_number = path.split(\"/\")[-1].split(\".\")[0]\n",
    "        print(file_number)\n",
    "        im.fromarray(circle).save(f\"./data/unlabeled_coins/{file_number}_{i}.jpg\")\n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### label hd coins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dir = \"./data/hd_coins/\"\n",
    "source_dir = \"./data/labeled_coins/\"\n",
    "unlabeled_dir = \"./data/unlabeled_coins/\"\n",
    "for d in os.listdir(source_dir):\n",
    "    class_dir = target_dir + d\n",
    "    if not os.path.exists(class_dir):\n",
    "        os.mkdir(class_dir)\n",
    "    \n",
    "    for file in os.listdir(source_dir+d):\n",
    "        src_file = unlabeled_dir+file\n",
    "        dst_file = target_dir + d+\"/\"+file\n",
    "        os.rename(src_file, dst_file)\n",
    "        # print(dst_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iapr_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
