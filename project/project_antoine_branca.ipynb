{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy\n",
    "!pip install matplotlib\n",
    "!pip install scikit-image\n",
    "!pip install pillow\n",
    "!pip install opencv-python\n",
    "!pip install timm\n",
    "!pip install tqdm\n",
    "# Check is at least python 3.9\n",
    "import sys \n",
    "assert (sys.version_info.major == 3) and (sys.version_info.minor == 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from typing import Callable\n",
    "import os\n",
    "from datetime import datetime\n",
    "from enum import Enum\n",
    "import random\n",
    "from skimage.color import rgb2gray, rgb2hsv\n",
    "from skimage import filters\n",
    "from skimage import segmentation\n",
    "from skimage.morphology import remove_small_holes, remove_small_objects\n",
    "import cv2 as cv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import timm\n",
    "import torchvision\n",
    "from torchvision.models.vision_transformer import vit_b_16\n",
    "from torchvision.models import ViT_B_16_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "\n",
    "# Get os name\n",
    "os_name = platform.system().lower()\n",
    "num_workers = 8\n",
    "\n",
    "# OS X\n",
    "if 'darwin' in os_name:\n",
    "    print(\"Detected OS X\")\n",
    "    %pip install torch==1.8.1 torchvision==0.9.1 torchaudio==0.8.1\n",
    "# Linux \n",
    "elif 'linux' in os_name:\n",
    "    print(\"Detected Linux\")\n",
    "    %pip install torch==1.8.1 torchvision==0.9.1 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "# Windows \n",
    "else:\n",
    "    print(\"Detected Windows\")\n",
    "    num_workers = 0  # Hard fix for Windows users\n",
    "    %pip install torch==1.12.0 torchvision==0.13 -f https://download.pytorch.org/whl/torch_stable.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageType(Enum):\n",
    "    NEUTRAL = \"1. neutral_bg\"\n",
    "    NOISY = \"2. noisy_bg\"\n",
    "    HAND = \"3. hand\"\n",
    "    NEUTRAL_OOD = \"4. neutral_bg_outliers\"\n",
    "    NOISY_OOD = \"5. noisy_bg_outliers\"\n",
    "    HAND_OOD = \"6. hand_outliers\"\n",
    "    \n",
    "def loadImageOfType(type: ImageType, downsample: int = 1, grayscale: bool = False):\n",
    "    # directory = f\"./data/train/{type}\"\n",
    "    directory = os.path.join(\".\", \"data\", \"train\", type.value)\n",
    "    images = os.listdir(directory)\n",
    "    img = np.array(Image.open(os.path.join(directory, random.choice(images)))) \n",
    "    if downsample > 1:\n",
    "        img = img[::downsample, ::downsample, :]\n",
    "    if grayscale:\n",
    "        img = (rgb2gray(img)*255).astype(np.uint8)\n",
    "        \n",
    "    # img = filters.sobel(img)\n",
    "    \n",
    "    return img\n",
    "        \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_circles(circle_array):\n",
    "    # print(circle_array)\n",
    "    # Convert the array to a NumPy array\n",
    "    \n",
    "    # Find unique center coordinates\n",
    "    unique_centers, unique_indices = np.unique(circle_array[:, :2], axis=0, return_index=True)\n",
    "    # print(unique_indices)\n",
    "    \n",
    "    # Get the indices of circles with largest radius for each unique center\n",
    "    largest_circles = []\n",
    "    for center in unique_centers:\n",
    "      largest_circle = np.array((center[0], center[1], 0))\n",
    "      for j in range(len(circle_array)):\n",
    "        circle = circle_array[j]\n",
    "        if (circle[0] == center[0] and circle[1]==center[1] and circle[2] > largest_circle[2]):\n",
    "          largest_circle[2] = circle[2] \n",
    "      largest_circles.append(largest_circle)\n",
    "  \n",
    "    # print(largest_circles)\n",
    "               \n",
    "      \n",
    "\n",
    "    # # Convert the list of indices to a NumPy array\n",
    "    # max_radius_indices = np.array(max_radius_indices)\n",
    "    # print(max_radius_indices)\n",
    "    \n",
    "    return np.array(largest_circles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the input is a cv image so x and y are swapped\n",
    "def extract_circles_images(x, y, r, img, down):\n",
    "    factor = r + 10\n",
    "    left = (x - factor)*down\n",
    "    right = (x + factor)*down\n",
    "    up = (y - factor)*down\n",
    "    bottom = (y + factor)*down\n",
    "    output = img.copy()\n",
    "    output[:, :, 0] = img[:, :, 2]\n",
    "    output[:, :, 2] = img[:, :, 0]\n",
    "    return output[up:bottom, left:right, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_circles(path, debug = False):\n",
    "    img = cv.imread(path)\n",
    "    full_size_img = img.copy()\n",
    "    down = 3\n",
    "    size = (int(img.shape[1]/down), int(img.shape[0]/down))\n",
    "    img = cv.resize(img, size, interpolation=cv.INTER_LINEAR)\n",
    "\n",
    "    output = img.copy()\n",
    "    output[:, :, 0] = img[:, :, 2]\n",
    "    output[:, :, 2] = img[:, :, 0]\n",
    "    img[:, :, 2] = 0\n",
    "\n",
    "\n",
    "\t# canny = cv.Canny(gray, 100, 200)\n",
    "\t# plt.imshow(canny, cmap=\"gray\")\n",
    "\t# plt.show()\n",
    "\n",
    "\n",
    "    gray = cv.blur(cv.cvtColor(img, cv.COLOR_BGR2GRAY), (8, 8))\n",
    "\n",
    "    # detect circles in the image\n",
    "    circles = cv.HoughCircles(gray, cv.HOUGH_GRADIENT_ALT, dp=1, minDist = 50, minRadius=50, maxRadius=200, param1=5, param2=0.6)\n",
    "    # ensure at least some circles were found\n",
    "    circles_imgs = []\n",
    "    if circles is not None:\n",
    "    # convert the (x, y) coordinates and radius of the circles to integers\n",
    "        circles = np.round(circles[0, :]).astype(\"int\")\n",
    "        circles = filter_circles(circles)\n",
    "        print(f\"detected {len(circles)} circles\")\n",
    "    \n",
    "        for (x, y, r) in circles:\n",
    "            # print(x, y, r)\n",
    "            # draw the circle in the output image, then draw a rectangle\n",
    "                # corresponding to the center of the circle\n",
    "            cv.circle(output, (x, y), r, (0, 255, 0), 4)\n",
    "            cv.rectangle(output, (x - 5, y - 5), (x + 5, y + 5), (0, 255, 0), -1)\n",
    "            new_circle = extract_circles_images(x, y, r, full_size_img, down)\n",
    "            circles_imgs.append(new_circle)\n",
    "            if debug:\n",
    "                plt.imshow(new_circle)\n",
    "                plt.show()\n",
    "            # circles_imgs.append(extract_circles_images(x, y, r, output))\n",
    "    \n",
    "        # show the output image\n",
    "    if debug:\n",
    "        plt.imshow(output)\n",
    "        plt.show()\n",
    "    return circles_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_data_paths():\n",
    "    training_paths = []\n",
    "    base_dir = \"./data/train/\"\n",
    "    for d in os.listdir(base_dir):\n",
    "        training_dir = f\"{base_dir}/{d}\"\n",
    "        for path in os.listdir(training_dir):\n",
    "            file_path = f\"{training_dir}/{path}\"\n",
    "            training_paths.append(file_path)\n",
    "            # print(file_path)\n",
    "    return training_paths\n",
    "        \n",
    "# get_training_data_paths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_for_image(path):\n",
    "    filename = path.split(\"/\")[-1].split(\".\")[0]\n",
    "\n",
    "    data = np.genfromtxt('./data/train_labels.csv', delimiter=',', dtype=str)\n",
    "\n",
    "# Assume the first column contains the strings you want to search through\n",
    "    first_column = data[:, 0]\n",
    "\n",
    "    # Find the index of the first entry that matches your string\n",
    "    index = np.where(first_column == filename)[0]\n",
    "    \n",
    "    if index.size > 0:\n",
    "        # print(f\"The first entry matching '{filename}' is at index {index[0]}.\")\n",
    "        #we add 0 in order to account for non coins\n",
    "        label_vector = np.append(data[index[0]][1:], 0)\n",
    "        # print(label_vector)\n",
    "        return torch.from_numpy(label_vector.astype(np.float32))\n",
    "        # You can access the corresponding row using data[index[0]]\n",
    "    else:\n",
    "        # print(f\"No entry matching '{filename}' found.\")\n",
    "        return torch.zeros(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = \"./data/train/1. neutral_bg//\"\n",
    "# d = \"./data/train/2. noisy_bg///\"\n",
    "# d = \"./data/train/3. hand///\"\n",
    "d = \"./data/train/5. noisy_bg_outliers/\"\n",
    "# d = \"./data/train/6. hand_outliers///\"\n",
    "# d = \"./data/test//\"\n",
    "# for f in os.listdir(d):\n",
    "\n",
    "paths = get_training_data_paths()\n",
    "p = paths[0]\n",
    "if get_label_for_image(p).shape[0] == 0:\n",
    "    print(\"wrong filename\")\n",
    "\n",
    "circles = find_circles(paths[0], debug=True)\n",
    "# for path in get_training_data_paths():\n",
    "# img = cv.imread(f\"{d}/{f}\")[::3, ::3].astype(np.uint8)\n",
    "# img[:, :, 1] = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f'Using {device} for inference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet152', pretrained=True)\n",
    "resnet152 = torchvision.models.resnet152(weights=torchvision.models.ResNet152_Weights.IMAGENET1K_V2).to(device)\n",
    "def extract_features(input_image):\n",
    "    # or any of these variants\n",
    "    # model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet34', pretrained=True)\n",
    "    # model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=True)\n",
    "    # model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet101', pretrained=True)\n",
    "    # model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet152', pretrained=True)\n",
    "    resnet152.eval()\n",
    "    feature_extractor = torch.nn.Sequential(*list(resnet152.children())[:-1])\n",
    "\n",
    "    image_dim = torch.tensor([input_image.shape[0]]).to(device)\n",
    "    # print(image_dim)\n",
    "\n",
    "    input_image = Image.fromarray(input_image)\n",
    "    # input_image.show()\n",
    "    preprocess = transforms.Compose([\n",
    "        # transforms.Resize(256),\n",
    "        transforms.CenterCrop(850),\n",
    "        transforms.ToTensor(),\n",
    "        # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    input_tensor = preprocess(input_image)\n",
    "    \n",
    "    # plt.imshow(input_tensor.permute(1, 2, 0))\n",
    "    # plt.show()\n",
    "    \n",
    "    input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
    "\n",
    "    # move the input and model to GPU for speed if available\n",
    "\n",
    "    input_batch = input_batch.to(device)\n",
    "    feature_extractor.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        features = feature_extractor(input_batch)\n",
    "    # Tensor of shape 1000, with confidence scores over ImageNet's 1000 classes\n",
    "    # print(output[0])\n",
    "    # The output has unnormalized scores. To get probabilities, you can run a softmax on it.\n",
    "    # probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
    "    features = torch.flatten(features)\n",
    "    # features = torch.cat((features, image_dim))\n",
    "\n",
    "    # print(features.size())\n",
    "    return features\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for circle in circles:\n",
    "    print(extract_features(circle).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_data_paths():\n",
    "    test_paths = []\n",
    "    base_dir = \"./data/test/\"\n",
    "    for path in os.listdir(base_dir):\n",
    "        file_path = f\"{base_dir}/{path}\"\n",
    "        test_paths.append(file_path)\n",
    "            # print(file_path)\n",
    "    return test_paths\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training on individual coin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"chf_5\", \"chf_2\", \"chf_1\", \"chf_0.5\", \"chf_0.2\", \"chf_0.1\", \"chf_0.05\", \"eur_2\", \"eur_1\", \"eur_0.5\", \"eur_0.2\", \"eur_0.1\", \"eur_0.05\", \"eur_0.02\", \"eur_0.01\", \"OOD\", \"bg\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_set_size():\n",
    "    size = 0\n",
    "    for index, c in enumerate(class_names):\n",
    "        labeled_coins_dir = \"./data/labeled_coins/\"\n",
    "        selected_dir = f\"{labeled_coins_dir}{c}\"\n",
    "        files = os.listdir(selected_dir)\n",
    "        size += len(files)\n",
    "    return size\n",
    "\n",
    "print(get_training_set_size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### background classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_set_size = get_training_set_size()\n",
    "\n",
    "trainX_bg = torch.zeros((data_set_size, 2048)).to(device)\n",
    "trainY_bg = torch.zeros(data_set_size).to(device)\n",
    "\n",
    "data_index = 0\n",
    "\n",
    "for index, c in enumerate(class_names):\n",
    "    print(f\"extracting class {index}\")\n",
    "    labeled_coins_dir = \"./data/labeled_coins/\"\n",
    "    selected_dir = f\"{labeled_coins_dir}{c}\"\n",
    "    files = os.listdir(selected_dir)\n",
    "    for j, file in enumerate(files):\n",
    "        selected_file_path = f\"{selected_dir}/{file}\"\n",
    "        coin = Image.open(selected_file_path)\n",
    "        # degrees = random.randint(0, 360)\n",
    "        # coin = coin.rotate(degrees, resample=Image.BICUBIC)\n",
    "    #     # coin.show()\n",
    "        \n",
    "    #     \"\"\"\n",
    "    #     extracting features + training\n",
    "    #     \"\"\"\n",
    "\n",
    "    #     optimizer.zero_grad()\n",
    "        x = extract_features(np.array(coin))\n",
    "        trainX_bg[data_index] = x\n",
    "        val_y = 0\n",
    "        if (index == class_names.index(\"bg\")):\n",
    "            val_y = 1\n",
    "        trainY_bg[data_index] = val_y\n",
    "\n",
    "        \n",
    "        data_index += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_classifier = torch.nn.Sequential( \n",
    "    torch.nn.Linear(in_features = 2048, out_features = 512), \n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(in_features = 512, out_features = 1), \n",
    "    torch.nn.Sigmoid()\n",
    ")\n",
    "\n",
    "bg_classifier = bg_classifier.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_bg = torch.nn.BCELoss()\n",
    "optimizer_bg = torch.optim.Adam(bg_classifier.parameters(), lr=5e-4)\n",
    "\n",
    "\n",
    "trainY_bg = trainY_bg.unsqueeze(0).view(-1, 1)\n",
    "# print(trainY_ood)\n",
    "\n",
    "\n",
    "nb_epochs = 1200\n",
    "\n",
    "for epoch in range(nb_epochs):\n",
    "    optimizer_bg.zero_grad()\n",
    "            \n",
    "    pred_bg = bg_classifier(trainX_bg)\n",
    "    # print(pred_ood)\n",
    "    # print(pred.shape)\n",
    "    loss_bg = criterion_bg(pred_bg, trainY_bg.to(device)) \n",
    "    loss_bg.backward() \n",
    "    # print(f\"loss at epoch {epoch} - {loss}\")\n",
    "    if epoch %50 == 0:\n",
    "        print(f\"loss at {epoch} - {loss_bg}\")\n",
    "    optimizer_bg.step() \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training ood classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_size = get_training_set_size()\n",
    "\n",
    "trainX_ood = torch.zeros((data_set_size, 2048)).to(device)\n",
    "trainY_ood = torch.zeros(data_set_size).to(device)\n",
    "\n",
    "data_index = 0\n",
    "\n",
    "for index, c in enumerate(class_names):\n",
    "    print(f\"extracting class {index}\")\n",
    "    labeled_coins_dir = \"./data/labeled_coins/\"\n",
    "    selected_dir = f\"{labeled_coins_dir}{c}\"\n",
    "    files = os.listdir(selected_dir)\n",
    "    for j, file in enumerate(files):\n",
    "        selected_file_path = f\"{selected_dir}/{file}\"\n",
    "        coin = Image.open(selected_file_path)\n",
    "        # degrees = random.randint(0, 360)\n",
    "        # coin = coin.rotate(degrees, resample=Image.BICUBIC)\n",
    "    #     # coin.show()\n",
    "        \n",
    "    #     \"\"\"\n",
    "    #     extracting features + training\n",
    "    #     \"\"\"\n",
    "\n",
    "    #     optimizer.zero_grad()\n",
    "        x = extract_features(np.array(coin))\n",
    "        trainX_ood[data_index] = x\n",
    "        val_y = 0\n",
    "        if (index == class_names.index(\"OOD\")):\n",
    "            val_y = 1\n",
    "        trainY_ood[data_index] = val_y\n",
    "\n",
    "        \n",
    "        data_index += 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ood_classifier = torch.nn.Sequential( \n",
    "    torch.nn.Linear(in_features = 2048, out_features = 512), \n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(in_features = 512, out_features = 1), \n",
    "    torch.nn.Sigmoid()\n",
    ")\n",
    "\n",
    "ood_classifier = ood_classifier.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_ood = torch.nn.BCELoss()\n",
    "optimizer_ood = torch.optim.Adam(ood_classifier.parameters(), lr=5e-4)\n",
    "\n",
    "\n",
    "trainY_ood = trainY_ood.unsqueeze(0).view(-1, 1)\n",
    "# print(trainY_ood)\n",
    "\n",
    "\n",
    "nb_epochs = 2000\n",
    "\n",
    "for epoch in range(nb_epochs):\n",
    "    optimizer_ood.zero_grad()\n",
    "            \n",
    "    pred_ood = ood_classifier(trainX_ood)\n",
    "    # print(pred_ood)\n",
    "    # print(pred.shape)\n",
    "    loss_ood = criterion_ood(pred_ood, trainY_ood.to(device)) \n",
    "    loss_ood.backward() \n",
    "    # print(f\"loss at epoch {epoch} - {loss}\")\n",
    "    if epoch %50 == 0:\n",
    "        print(f\"loss at {epoch} - {loss_ood}\")\n",
    "    optimizer_ood.step() \n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training chf/eur classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_coins_dir = \"./data/labeled_coins/\"\n",
    "data_set_size = get_training_set_size() - len(os.listdir(labeled_coins_dir+\"bg\")) - len(os.listdir(labeled_coins_dir+\"OOD\"))\n",
    "\n",
    "trainX = torch.zeros((data_set_size, 2048)).to(device)\n",
    "trainY = torch.zeros(data_set_size).to(device)\n",
    "\n",
    "data_index = 0\n",
    "\n",
    "\n",
    "for index, c in enumerate(class_names):\n",
    "    if index >= len(class_names) - 2: continue\n",
    "\n",
    "    print(f\"extracting class {index}\")\n",
    "    selected_dir = f\"{labeled_coins_dir}{c}\"\n",
    "    files = os.listdir(selected_dir)\n",
    "    for j, file in enumerate(files):\n",
    "        target = torch.tensor([index]).to(device)\n",
    "\n",
    "        selected_file_path = f\"{selected_dir}/{file}\"\n",
    "        coin = Image.open(selected_file_path)\n",
    "        # degrees = random.randint(0, 360)\n",
    "        # coin = coin.rotate(degrees, resample=Image.BICUBIC)\n",
    "    #     # coin.show()\n",
    "        \n",
    "    #     \"\"\"\n",
    "    #     extracting features + training\n",
    "    #     \"\"\"\n",
    "\n",
    "    #     optimizer.zero_grad()\n",
    "        x = extract_features(np.array(coin))\n",
    "        trainX[data_index] = x\n",
    "        trainY[data_index] = index\n",
    "\n",
    "        \n",
    "        data_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = torch.nn.Sequential( \n",
    "    torch.nn.Linear(in_features = 2048, out_features = 512), \n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(in_features = 512, out_features = 15), \n",
    "\n",
    ")\n",
    "\n",
    "linear = linear.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "criterion = torch.nn.CrossEntropyLoss() \n",
    "optimizer = torch.optim.Adam(linear.parameters(), lr=5e-4)\n",
    "\n",
    "nb_epochs = 1750\n",
    "\n",
    "for epoch in range(nb_epochs):\n",
    "    optimizer.zero_grad()\n",
    "            \n",
    "    pred = linear(trainX)\n",
    "    # print(pred.shape)\n",
    "    loss = criterion(pred, trainY.to(device).long()) \n",
    "    loss.backward() \n",
    "    # print(f\"loss at epoch {epoch} - {loss}\")\n",
    "    if epoch %50 == 0:\n",
    "        print(f\"loss at {epoch} - {loss}\")\n",
    "    optimizer.step() \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainY.shape)\n",
    "print(trainY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_header = \"id,5CHF,2CHF,1CHF,0.5CHF,0.2CHF,0.1CHF,0.05CHF,2EUR,1EUR,0.5EUR,0.2EUR,0.1EUR,0.05EUR,0.02EUR,0.01EUR,OOD\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_to_filename(path):\n",
    "    return path.split(\"/\")[-1].split(\".\")[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### filter functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_radius(coin, min_radius, max_radius, debug=False):\n",
    "    img = (rgb2gray(coin)*255).astype(np.uint8)\n",
    "    down = 2\n",
    "    img = cv.blur(img, (16, 16))[::down, ::down]\n",
    "    \n",
    "    min_r = int((min_radius*0.9)//down)\n",
    "    max_r = int((max_radius*1.5)//down)\n",
    "    \n",
    "    circle = cv.HoughCircles(img, cv.HOUGH_GRADIENT_ALT, dp=1, minDist = 50, minRadius=min_r, maxRadius=max_r, param1=50, param2=0.8)\n",
    "    # print(circle)\n",
    "    \n",
    "    if circle is not None:\n",
    "# convert the (x, y) coordinates and radius of the circles to integers\n",
    "        circles = np.round(circle[0, :]).astype(\"int\")\n",
    "        circles = filter_circles(circles)\n",
    "        # print(f\"detected {len(circles)} circles\")\n",
    "    \n",
    "        for (x, y, r) in circles:\n",
    "            # print(x, y, r)\n",
    "            # draw the circle in the output image, then draw a rectangle\n",
    "                # corresponding to the center of the circle\n",
    "            radius = down*r\n",
    "            if debug:\n",
    "                # print()\n",
    "                cv.circle(coin, (down*x, down*y), down*r, (0, 255, 0), 4)\n",
    "                plt.title(f\"radius: {radius}\")\n",
    "                plt.imshow(coin)\n",
    "                plt.show()\n",
    "            return radius\n",
    "    else:\n",
    "        if debug:\n",
    "            print(\"no circle found\")\n",
    "        return 0\n",
    "            # new_circle = extract_circles_images(x, y, r, full_size_img, down)\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_radius_eur_cents(coin, min_radius, max_radius, debug=False):\n",
    "    img = (rgb2gray(coin)*255).astype(np.uint8)\n",
    "    img = cv.blur(img, (16, 16))[::3, ::3]\n",
    "    \n",
    "    min_r = int((min_radius*0.9)//3)\n",
    "    max_r = int((max_radius*1.1)//3)\n",
    "    \n",
    "    circle = cv.HoughCircles(img, cv.HOUGH_GRADIENT_ALT, dp=1, minDist = 50, minRadius=min_r, maxRadius=max_r, param1=50, param2=0.6)\n",
    "    # print(circle)\n",
    "    \n",
    "    if circle is not None:\n",
    "# convert the (x, y) coordinates and radius of the circles to integers\n",
    "        circles = np.round(circle[0, :]).astype(\"int\")\n",
    "        circles = filter_circles(circles)\n",
    "        # print(f\"detected {len(circles)} circles\")\n",
    "    \n",
    "        for (x, y, r) in circles:\n",
    "            # print(x, y, r)\n",
    "            # draw the circle in the output image, then draw a rectangle\n",
    "                # corresponding to the center of the circle\n",
    "            radius = 3*r\n",
    "            if debug:\n",
    "                # print()\n",
    "                cv.circle(coin, (3*x, 3*y), 3*r, (0, 255, 0), 4)\n",
    "                plt.title(f\"radius: {radius}\")\n",
    "                plt.imshow(coin)\n",
    "                plt.show()\n",
    "            return radius\n",
    "    else:\n",
    "        if debug:\n",
    "            print(\"no circle found\")\n",
    "        return 0\n",
    "            # new_circle = extract_circles_images(x, y, r, full_size_img, down)\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_chf_cents(coin, pred_class, debug=False):\n",
    "    previous_class = pred_class\n",
    "    cents_20_radius = 240\n",
    "    cents_10_radius = 228\n",
    "    cents_50_radius = 208\n",
    "    \n",
    "    radius = find_radius(coin, min_radius=cents_50_radius, max_radius=cents_10_radius, debug=debug)\n",
    "    if radius < 150: return pred_class\n",
    "        \n",
    "    values = np.array((cents_50_radius, cents_20_radius, cents_10_radius))\n",
    "    classes = [3, 4, 5]\n",
    "    pred = classes[np.argmin(np.abs(values - radius))]\n",
    "    if debug:\n",
    "        print(f\"returning {class_names[pred]}, before {class_names[previous_class]}\")\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_chf_francs(coin, pred_class, debug=False):\n",
    "    francs_2_radius = 315\n",
    "    francs_1_radius = 265\n",
    "    \n",
    "    radius = find_radius(coin, min_radius=francs_1_radius, max_radius=francs_2_radius, debug=debug)\n",
    "    if radius < 240: return pred_class\n",
    "        \n",
    "    values = np.array((francs_2_radius, francs_1_radius))\n",
    "    classes = [1, 2]\n",
    "    pred = classes[np.argmin(np.abs(values - radius))]\n",
    "    if debug:\n",
    "        print(f\"returning {class_names[pred]} - before {class_names[pred_class]}\")\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_eur_cents(coin, pred_class, debug=False):\n",
    "    cents_1_radius = 192\n",
    "    cents_2_radius = 222\n",
    "    cents_5_radius = 249\n",
    "    \n",
    "    radius = find_radius_eur_cents(coin, min_radius=cents_1_radius, max_radius=cents_5_radius, debug=debug)\n",
    "    if radius < 170: return pred_class\n",
    "        \n",
    "    values = np.array((cents_5_radius, cents_2_radius, cents_1_radius))\n",
    "    classes = [12, 13, 14]\n",
    "    pred = classes[np.argmin(np.abs(values - radius))]\n",
    "    if debug:\n",
    "        print(f\"returning {class_names[pred]} - before {class_names[pred_class]}\")\n",
    "    return pred\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_eur_1_2(coin, pred_class, debug=False):\n",
    "    eur_2_radius = 292\n",
    "    eur_1_radius = 266\n",
    "    \n",
    "    \n",
    "    \n",
    "    radius = find_radius(coin, min_radius=eur_1_radius, max_radius=eur_2_radius, debug=debug)\n",
    "    if radius < 240: return pred_class\n",
    "        \n",
    "    values = np.array((eur_2_radius, eur_1_radius))\n",
    "    classes = [7, 8]\n",
    "    pred = classes[np.argmin(np.abs(values - radius))]\n",
    "    if debug:\n",
    "        print(f\"returning {class_names[pred]} - before {class_names[pred_class]}\")\n",
    "    return pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.random.randint(0, 17)\n",
    "csv_file = csv_header\n",
    "csv_file += \"\\n\"\n",
    "with torch.no_grad():\n",
    "# index = 16\n",
    "    linear.eval()\n",
    "    ood_classifier.eval()\n",
    "    bg_classifier.eval()\n",
    "\n",
    "    # labeled_coins_dir = \"./data/labeled_coins/\"\n",
    "    # selected_dir = f\"{labeled_coins_dir}{class_names[index]}\"\n",
    "    # files = os.listdir(selected_dir)\n",
    "    # selected_file = random.choice(files)\n",
    "    # selected_file_path = f\"{selected_dir}/{selected_file}\"\n",
    "    # print(selected_file_path)\n",
    "\n",
    "    for i, path in enumerate(get_test_data_paths()):\n",
    "        print(path)\n",
    "    \n",
    "        # path = \"./data/test/L0000113.JPG\"\n",
    "        coins = find_circles(path)\n",
    "        # coins = find_circles(\"./data/train/1. neutral_bg/L1010277.JPG\")\n",
    "        \n",
    "        p = np.zeros(16, dtype=np.uint8)\n",
    "        for coin in coins:\n",
    "            shape = coin.shape\n",
    "            if shape[0] <10 or shape[1]<10: continue\n",
    "            # print(coin.shape)\n",
    "        \n",
    "            \n",
    "            \n",
    "            # coin = np.array(im.open(selected_file_path))\n",
    "            # coin.show()\n",
    "\n",
    "\n",
    "            x = extract_features(coin).to(device)\n",
    "            # print(x)\n",
    "            x = torch.unsqueeze(x, 0)\n",
    "\n",
    "            bg_pred = bg_classifier(x)\n",
    "            bg_class_pred = torch.round(bg_pred).item()\n",
    "            if bg_class_pred == 1: continue\n",
    "\n",
    "\n",
    "\n",
    "            ood_pred = ood_classifier(x)\n",
    "            ood_class_pred = torch.round(ood_pred).item()\n",
    "            if ood_class_pred == 1:\n",
    "                p[15] += 1\n",
    "                # plt.imshow(coin)\n",
    "                # plt.show()\n",
    "                continue\n",
    "            \n",
    "\n",
    "            pred_test = linear(x).flatten()\n",
    "            pred_class = torch.argmax(pred_test)\n",
    "            \n",
    "           \n",
    "            \n",
    "            \n",
    "            # proba = (torch.softmax(pred_test, dim=0)*100)\n",
    "            # max_proba = torch.max(proba).item()\n",
    "            # print(f\"{max_proba} - {class_names[pred_class]}\")\n",
    "            # if pred_class == 9:\n",
    "            #     plt.title(class_names[pred_class.item()])\n",
    "            #     plt.imshow(coin)\n",
    "            #     plt.show()\n",
    "            \n",
    "            # if max_proba < 0.7:\n",
    "            \n",
    "            if pred_class==3 or pred_class == 4 or pred_class == 5:\n",
    "                # print(\"checking chf cents\")\n",
    "                pred_class = test_chf_cents(coin, pred_class.item())\n",
    "\n",
    "            # if pred_class == 6 or pred_class == 0:\n",
    "            #     plt.title(class_names[pred_class])\n",
    "            #     plt.imshow(coin)\n",
    "            #     plt.show()\n",
    "            if pred_class == 12 or pred_class == 13 or pred_class == 14:\n",
    "                # print(\"checking eur cents\")\n",
    "                \n",
    "                pred_class = test_eur_cents(coin, pred_class.item())\n",
    "                \n",
    "            elif pred_class == 7 or pred_class == 8:\n",
    "                # print(\"checking eur cents\")\n",
    "                \n",
    "                pred_class = test_eur_1_2(coin, pred_class.item())\n",
    "\n",
    "            \n",
    "            elif pred_class == 1 or pred_class == 2:\n",
    "                # print(\"checking chf francs\")  \n",
    "                pred_class = test_chf_francs(coin, pred_class.item())\n",
    "            \n",
    "            # if pred_class == 4 or pred_class==5:\n",
    "            #     radius = find_radius(coin)\n",
    "            #     print(f\"radius: {radius}\")\n",
    "            #     if radius != 0:\n",
    "            #         if radius < 235:\n",
    "            #             pred_class = 4\n",
    "            #         elif radius < 220:\n",
    "            #             pred_class = 6\n",
    "            #         else: pred_calss = 5\n",
    "                \n",
    "            # print(pred_class)\n",
    "            \n",
    "            p[pred_class] += 1\n",
    "        # print(f\"pred {pred_class}\")\n",
    "        # print(f\"target: {index}\")\n",
    "        \n",
    "        # print(p)\n",
    "        p_string = np.array2string(p, separator=', ', precision=0).replace(\"[\", \"\").replace(\"]\", \"\")\n",
    "        csv_row = f\"{path_to_filename(path)},{p_string}\"\n",
    "        # print(csv_row)\n",
    "        print(csv_row)\n",
    "        csv_file += csv_row\n",
    "        csv_file += \"\\n\"\n",
    "\n",
    "with open('./data/submission.csv', 'w') as file:\n",
    "    # Write a string to the file\n",
    "    file.write(csv_file)\n",
    "    \n",
    "# print(csv_row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extracting all coins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image as im \n",
    "paths = get_training_data_paths()\n",
    "print(len(paths))\n",
    "\n",
    "# for path in paths:\n",
    "for path in paths:\n",
    "    circles =find_circles(path)\n",
    "    for i, circle in enumerate(circles):\n",
    "        file_number = path.split(\"/\")[-1].split(\".\")[0]\n",
    "        print(file_number)\n",
    "        im.fromarray(circle).save(f\"./data/unlabeled_coins/{file_number}_{i}.jpg\")\n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### label hd coins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dir = \"./data/hd_coins/\"\n",
    "source_dir = \"./data/labeled_coins/\"\n",
    "unlabeled_dir = \"./data/unlabeled_coins/\"\n",
    "for d in os.listdir(source_dir):\n",
    "    class_dir = target_dir + d\n",
    "    if not os.path.exists(class_dir):\n",
    "        os.mkdir(class_dir)\n",
    "    \n",
    "    for file in os.listdir(source_dir+d):\n",
    "        src_file = unlabeled_dir+file\n",
    "        dst_file = target_dir + d+\"/\"+file\n",
    "        os.rename(src_file, dst_file)\n",
    "        # print(dst_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = open('./data/submission.csv', 'r')\n",
    "lines = file1.readlines()\n",
    "file2 = open('./data/submission_ood_bg_classifier_tests_only_coins_confirmation.csv', 'r')\n",
    "lines2 = file2.readlines()\n",
    "\n",
    "diff = 0\n",
    "for i in range(len(lines2)):\n",
    "    if lines[i] != lines2[i]:\n",
    "        diff+=1\n",
    "        print(lines[i], lines2[i])\n",
    "print(diff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iapr_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
